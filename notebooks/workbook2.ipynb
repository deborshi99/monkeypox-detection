{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import cv2\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import Sequential\n",
    "from keras.activations import relu, sigmoid\n",
    "from keras.layers import Conv2D, Dense, Flatten, MaxPooling2D, Dropout\n",
    "from keras.losses import binary_crossentropy\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import scipy\n",
    "import os\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = \"../datasets/main_dataset/\"\n",
    "train_dir = os.path.join(base_dir, \"train\")\n",
    "test_dir = os.path.join(base_dir, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "def create_generator_with_augmented(train_dir, test_dir):\n",
    "    train_datagen = ImageDataGenerator(\n",
    "        rescale=1/255.0,\n",
    "        rotation_range=40,\n",
    "        horizontal_flip=True,\n",
    "        shear_range=0.3,\n",
    "        vertical_flip=True,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2\n",
    "    )\n",
    "    test_datagen = ImageDataGenerator(\n",
    "        rescale=1/255.0,\n",
    "        rotation_range=40,\n",
    "        horizontal_flip=True,\n",
    "        shear_range=0.3,\n",
    "        vertical_flip=True,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2\n",
    "    )\n",
    "\n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "        train_dir,\n",
    "        class_mode=\"binary\",\n",
    "        target_size=(224, 224),\n",
    "        batch_size=16\n",
    "    )\n",
    "\n",
    "    test_generator = test_datagen.flow_from_directory(\n",
    "        test_dir,\n",
    "        class_mode=\"binary\",\n",
    "        target_size=(224, 224),\n",
    "        batch_size=16\n",
    "    )\n",
    "    return train_generator, test_generator\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def create_generator_without_augmentation(train_dir, test_dir):\n",
    "    train_generator = image_dataset_from_directory(\n",
    "        train_dir,\n",
    "        label_mode=\"binary\",\n",
    "        image_size=(224, 224),\n",
    "        batch_size=16\n",
    "    )\n",
    "\n",
    "    test_generator = image_dataset_from_directory(\n",
    "        test_dir,\n",
    "        label_mode=\"binary\",\n",
    "        image_size=(224, 224),\n",
    "        batch_size=16\n",
    "    )\n",
    "    return train_generator, test_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(128, (3, 3), activation=relu, input_shape=(224, 224, 3)))\n",
    "    model.add(MaxPooling2D(2, 2))\n",
    "    model.add(Conv2D(128, (3, 3), activation=relu))\n",
    "    model.add(MaxPooling2D(2, 2))\n",
    "    model.add(Conv2D(128, (3, 3), activation=relu))\n",
    "    model.add(MaxPooling2D(2, 2))\n",
    "    model.add(Conv2D(128, (3, 3), activation=relu))\n",
    "    model.add(MaxPooling2D(2, 2))\n",
    "    # model.add(Conv2D(128, (3, 3), activation=relu))\n",
    "    # model.add(MaxPooling2D(2, 2))\n",
    "    # model.add(Conv2D(128, (3, 3), activation=relu))\n",
    "    # model.add(MaxPooling2D(2, 2))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    #model.add(Dense(1024, activation=relu))\n",
    "    model.add(Dense(512, activation=relu))\n",
    "    model.add(Dense(1, activation=sigmoid))\n",
    "\n",
    "    model.compile(loss=binary_crossentropy, optimizer=Adam(), metrics=[\"acc\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 222, 222, 128)     3584      \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 111, 111, 128)    0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 109, 109, 128)     147584    \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 54, 54, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 52, 52, 128)       147584    \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 26, 26, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 24, 24, 128)       147584    \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 12, 12, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 18432)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               9437696   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9,884,545\n",
      "Trainable params: 9,884,545\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-21 19:48:43.946153: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-21 19:48:44.011775: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-21 19:48:44.012002: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-21 19:48:44.012544: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-07-21 19:48:44.013381: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-21 19:48:44.013569: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-21 19:48:44.013693: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-21 19:48:45.033456: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-21 19:48:45.033672: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-21 19:48:45.033826: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-21 19:48:45.033955: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2638 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1650, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "model1 = create_model()\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 200 images belonging to 2 classes.\n",
      "Found 52 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator, test_generator = create_generator(train_dir, test_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-21 19:48:47.142266: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8401\n",
      "2022-07-21 19:48:48.137616: W tensorflow/core/common_runtime/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.17GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2022-07-21 19:48:48.137652: W tensorflow/core/common_runtime/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.17GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2022-07-21 19:48:48.751406: W tensorflow/core/common_runtime/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.17GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2022-07-21 19:48:48.751447: W tensorflow/core/common_runtime/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.17GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2022-07-21 19:48:48.910394: W tensorflow/core/common_runtime/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.09GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2022-07-21 19:48:48.910433: W tensorflow/core/common_runtime/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.09GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1/13 [=>............................] - ETA: 42s - loss: 0.6961 - acc: 0.2500"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-21 19:48:49.656880: W tensorflow/core/common_runtime/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.30GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2022-07-21 19:48:49.657147: W tensorflow/core/common_runtime/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.30GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2022-07-21 19:48:50.244489: W tensorflow/core/common_runtime/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.30GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2022-07-21 19:48:50.244524: W tensorflow/core/common_runtime/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.30GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 8s 354ms/step - loss: 0.8308 - acc: 0.5100 - val_loss: 0.6949 - val_acc: 0.5000\n",
      "Epoch 2/100\n",
      "13/13 [==============================] - 2s 172ms/step - loss: 0.6950 - acc: 0.5000 - val_loss: 0.6899 - val_acc: 0.5000\n",
      "Epoch 3/100\n",
      "13/13 [==============================] - 2s 179ms/step - loss: 0.6873 - acc: 0.5400 - val_loss: 0.7012 - val_acc: 0.5000\n",
      "Epoch 4/100\n",
      "13/13 [==============================] - 2s 172ms/step - loss: 0.7168 - acc: 0.5100 - val_loss: 0.6956 - val_acc: 0.5000\n",
      "Epoch 5/100\n",
      "13/13 [==============================] - 2s 175ms/step - loss: 0.6840 - acc: 0.5150 - val_loss: 0.6885 - val_acc: 0.5769\n",
      "Epoch 6/100\n",
      "13/13 [==============================] - 3s 185ms/step - loss: 0.7306 - acc: 0.5200 - val_loss: 0.6918 - val_acc: 0.5000\n",
      "Epoch 7/100\n",
      "13/13 [==============================] - 2s 180ms/step - loss: 0.6934 - acc: 0.5100 - val_loss: 0.6924 - val_acc: 0.5000\n",
      "Epoch 8/100\n",
      "13/13 [==============================] - 3s 183ms/step - loss: 0.6925 - acc: 0.4750 - val_loss: 0.6923 - val_acc: 0.5000\n",
      "Epoch 9/100\n",
      "13/13 [==============================] - 2s 176ms/step - loss: 0.6769 - acc: 0.5450 - val_loss: 0.6880 - val_acc: 0.5000\n",
      "Epoch 10/100\n",
      "13/13 [==============================] - 3s 196ms/step - loss: 0.6752 - acc: 0.5400 - val_loss: 0.6855 - val_acc: 0.5385\n",
      "Epoch 11/100\n",
      "13/13 [==============================] - 3s 184ms/step - loss: 0.6680 - acc: 0.5400 - val_loss: 0.6831 - val_acc: 0.5000\n",
      "Epoch 12/100\n",
      "13/13 [==============================] - 3s 185ms/step - loss: 0.6612 - acc: 0.5550 - val_loss: 0.6818 - val_acc: 0.5000\n",
      "Epoch 13/100\n",
      "13/13 [==============================] - 2s 185ms/step - loss: 0.6895 - acc: 0.5400 - val_loss: 0.6888 - val_acc: 0.5192\n",
      "Epoch 14/100\n",
      "13/13 [==============================] - 3s 190ms/step - loss: 0.6805 - acc: 0.5050 - val_loss: 0.6905 - val_acc: 0.5000\n",
      "Epoch 15/100\n",
      "13/13 [==============================] - 3s 188ms/step - loss: 0.6749 - acc: 0.5400 - val_loss: 0.6869 - val_acc: 0.5577\n",
      "Epoch 16/100\n",
      "13/13 [==============================] - 3s 193ms/step - loss: 0.6617 - acc: 0.5100 - val_loss: 0.6796 - val_acc: 0.5769\n",
      "Epoch 17/100\n",
      "13/13 [==============================] - 2s 190ms/step - loss: 0.7288 - acc: 0.5350 - val_loss: 0.6921 - val_acc: 0.5000\n",
      "Epoch 18/100\n",
      "13/13 [==============================] - 3s 188ms/step - loss: 0.6698 - acc: 0.5650 - val_loss: 0.6852 - val_acc: 0.5000\n",
      "Epoch 19/100\n",
      "13/13 [==============================] - 2s 179ms/step - loss: 0.6853 - acc: 0.5300 - val_loss: 0.6885 - val_acc: 0.5192\n",
      "Epoch 20/100\n",
      "13/13 [==============================] - 3s 185ms/step - loss: 0.6674 - acc: 0.5450 - val_loss: 0.7016 - val_acc: 0.5000\n",
      "Epoch 21/100\n",
      "13/13 [==============================] - 3s 187ms/step - loss: 0.6589 - acc: 0.4850 - val_loss: 0.6898 - val_acc: 0.5000\n",
      "Epoch 22/100\n",
      "13/13 [==============================] - 3s 187ms/step - loss: 0.6640 - acc: 0.5200 - val_loss: 0.6852 - val_acc: 0.5192\n",
      "Epoch 23/100\n",
      "13/13 [==============================] - 3s 182ms/step - loss: 0.6614 - acc: 0.5750 - val_loss: 0.6895 - val_acc: 0.5192\n",
      "Epoch 24/100\n",
      "13/13 [==============================] - 2s 179ms/step - loss: 0.6660 - acc: 0.5350 - val_loss: 0.6809 - val_acc: 0.5192\n",
      "Epoch 25/100\n",
      "13/13 [==============================] - 3s 209ms/step - loss: 0.6372 - acc: 0.5800 - val_loss: 0.6803 - val_acc: 0.5192\n",
      "Epoch 26/100\n",
      "13/13 [==============================] - 3s 186ms/step - loss: 0.6847 - acc: 0.5500 - val_loss: 0.6912 - val_acc: 0.5000\n",
      "Epoch 27/100\n",
      "13/13 [==============================] - 3s 186ms/step - loss: 0.6635 - acc: 0.5500 - val_loss: 0.6875 - val_acc: 0.5192\n",
      "Epoch 28/100\n",
      "13/13 [==============================] - 3s 195ms/step - loss: 0.6597 - acc: 0.5500 - val_loss: 0.6854 - val_acc: 0.5000\n",
      "Epoch 29/100\n",
      "13/13 [==============================] - 3s 183ms/step - loss: 0.7001 - acc: 0.5400 - val_loss: 0.6917 - val_acc: 0.5962\n",
      "Epoch 30/100\n",
      "13/13 [==============================] - 3s 186ms/step - loss: 0.6786 - acc: 0.5150 - val_loss: 0.6871 - val_acc: 0.5000\n",
      "Epoch 31/100\n",
      "13/13 [==============================] - 3s 196ms/step - loss: 0.7007 - acc: 0.5550 - val_loss: 0.8101 - val_acc: 0.5000\n",
      "Epoch 32/100\n",
      "13/13 [==============================] - 2s 181ms/step - loss: 0.6766 - acc: 0.5500 - val_loss: 0.6912 - val_acc: 0.5000\n",
      "Epoch 33/100\n",
      "13/13 [==============================] - 3s 195ms/step - loss: 0.6809 - acc: 0.4950 - val_loss: 0.6927 - val_acc: 0.5000\n",
      "Epoch 34/100\n",
      "13/13 [==============================] - 3s 200ms/step - loss: 0.6738 - acc: 0.5500 - val_loss: 0.6861 - val_acc: 0.5385\n",
      "Epoch 35/100\n",
      "13/13 [==============================] - 3s 207ms/step - loss: 0.6970 - acc: 0.5450 - val_loss: 0.7163 - val_acc: 0.5000\n",
      "Epoch 36/100\n",
      "13/13 [==============================] - 3s 197ms/step - loss: 0.6715 - acc: 0.5550 - val_loss: 0.6933 - val_acc: 0.5000\n",
      "Epoch 37/100\n",
      "13/13 [==============================] - 3s 193ms/step - loss: 0.6762 - acc: 0.5350 - val_loss: 0.6933 - val_acc: 0.5000\n",
      "Epoch 38/100\n",
      "13/13 [==============================] - 3s 204ms/step - loss: 0.6705 - acc: 0.5500 - val_loss: 0.6934 - val_acc: 0.5000\n",
      "Epoch 39/100\n",
      "13/13 [==============================] - 3s 199ms/step - loss: 0.6906 - acc: 0.5500 - val_loss: 0.6933 - val_acc: 0.5000\n",
      "Epoch 40/100\n",
      "13/13 [==============================] - 3s 187ms/step - loss: 0.6753 - acc: 0.5500 - val_loss: 0.6922 - val_acc: 0.6346\n",
      "Epoch 41/100\n",
      "13/13 [==============================] - 3s 201ms/step - loss: 0.6611 - acc: 0.5650 - val_loss: 0.6905 - val_acc: 0.5385\n",
      "Epoch 42/100\n",
      "13/13 [==============================] - 3s 191ms/step - loss: 0.6638 - acc: 0.5600 - val_loss: 0.6874 - val_acc: 0.5192\n",
      "Epoch 43/100\n",
      "13/13 [==============================] - 3s 194ms/step - loss: 0.6775 - acc: 0.5700 - val_loss: 0.6925 - val_acc: 0.5000\n",
      "Epoch 44/100\n",
      "13/13 [==============================] - 3s 200ms/step - loss: 0.6589 - acc: 0.5650 - val_loss: 0.6915 - val_acc: 0.5000\n",
      "Epoch 45/100\n",
      "13/13 [==============================] - 3s 196ms/step - loss: 0.6912 - acc: 0.5650 - val_loss: 0.6912 - val_acc: 0.5000\n",
      "Epoch 46/100\n",
      "13/13 [==============================] - 3s 187ms/step - loss: 0.6541 - acc: 0.5650 - val_loss: 0.6891 - val_acc: 0.5577\n",
      "Epoch 47/100\n",
      "13/13 [==============================] - 3s 195ms/step - loss: 0.6651 - acc: 0.5650 - val_loss: 0.6938 - val_acc: 0.5000\n",
      "Epoch 48/100\n",
      "13/13 [==============================] - 3s 198ms/step - loss: 0.6527 - acc: 0.5550 - val_loss: 0.6966 - val_acc: 0.5000\n",
      "Epoch 49/100\n",
      "13/13 [==============================] - 3s 192ms/step - loss: 0.6534 - acc: 0.5600 - val_loss: 0.6937 - val_acc: 0.5000\n",
      "Epoch 50/100\n",
      "13/13 [==============================] - 3s 190ms/step - loss: 0.6702 - acc: 0.5400 - val_loss: 0.6939 - val_acc: 0.5000\n",
      "Epoch 51/100\n",
      "13/13 [==============================] - 3s 196ms/step - loss: 0.6718 - acc: 0.5600 - val_loss: 0.6919 - val_acc: 0.5192\n",
      "Epoch 52/100\n",
      "13/13 [==============================] - 3s 191ms/step - loss: 0.6570 - acc: 0.5900 - val_loss: 0.6825 - val_acc: 0.5769\n",
      "Epoch 53/100\n",
      "13/13 [==============================] - 3s 203ms/step - loss: 0.6662 - acc: 0.5400 - val_loss: 0.6925 - val_acc: 0.4808\n",
      "Epoch 54/100\n",
      "13/13 [==============================] - 3s 202ms/step - loss: 0.6666 - acc: 0.5600 - val_loss: 0.7164 - val_acc: 0.5000\n",
      "Epoch 55/100\n",
      "13/13 [==============================] - 3s 215ms/step - loss: 0.6850 - acc: 0.5650 - val_loss: 0.6933 - val_acc: 0.5000\n",
      "Epoch 56/100\n",
      "13/13 [==============================] - 3s 215ms/step - loss: 0.6628 - acc: 0.5800 - val_loss: 0.7030 - val_acc: 0.5577\n",
      "Epoch 57/100\n",
      "13/13 [==============================] - 3s 210ms/step - loss: 0.6557 - acc: 0.5650 - val_loss: 0.6891 - val_acc: 0.5192\n",
      "Epoch 58/100\n",
      "13/13 [==============================] - 3s 201ms/step - loss: 0.6722 - acc: 0.5400 - val_loss: 0.6859 - val_acc: 0.5385\n",
      "Epoch 59/100\n",
      "13/13 [==============================] - 3s 222ms/step - loss: 0.6645 - acc: 0.5400 - val_loss: 0.6890 - val_acc: 0.5000\n",
      "Epoch 60/100\n",
      "13/13 [==============================] - 3s 219ms/step - loss: 0.6654 - acc: 0.5900 - val_loss: 0.6824 - val_acc: 0.5000\n",
      "Epoch 61/100\n",
      "13/13 [==============================] - 3s 213ms/step - loss: 0.6624 - acc: 0.5700 - val_loss: 0.7041 - val_acc: 0.5000\n",
      "Epoch 62/100\n",
      "13/13 [==============================] - 3s 203ms/step - loss: 0.6722 - acc: 0.4900 - val_loss: 0.7003 - val_acc: 0.5000\n",
      "Epoch 63/100\n",
      "13/13 [==============================] - 3s 206ms/step - loss: 0.6720 - acc: 0.5300 - val_loss: 0.6895 - val_acc: 0.5000\n",
      "Epoch 64/100\n",
      "13/13 [==============================] - 3s 200ms/step - loss: 0.6682 - acc: 0.5650 - val_loss: 0.6890 - val_acc: 0.5000\n",
      "Epoch 65/100\n",
      "13/13 [==============================] - 3s 194ms/step - loss: 0.6601 - acc: 0.5800 - val_loss: 0.6811 - val_acc: 0.5962\n",
      "Epoch 66/100\n",
      "13/13 [==============================] - 3s 198ms/step - loss: 0.6784 - acc: 0.5800 - val_loss: 0.6971 - val_acc: 0.5000\n",
      "Epoch 67/100\n",
      "13/13 [==============================] - 3s 221ms/step - loss: 0.6794 - acc: 0.5400 - val_loss: 0.6920 - val_acc: 0.5192\n",
      "Epoch 68/100\n",
      "13/13 [==============================] - 3s 210ms/step - loss: 0.6544 - acc: 0.5750 - val_loss: 0.6829 - val_acc: 0.5577\n",
      "Epoch 69/100\n",
      "13/13 [==============================] - 3s 219ms/step - loss: 0.6602 - acc: 0.5450 - val_loss: 0.6816 - val_acc: 0.5769\n",
      "Epoch 70/100\n",
      "13/13 [==============================] - 3s 205ms/step - loss: 0.6945 - acc: 0.5450 - val_loss: 0.9198 - val_acc: 0.5000\n",
      "Epoch 71/100\n",
      "13/13 [==============================] - 3s 205ms/step - loss: 0.6972 - acc: 0.5100 - val_loss: 0.6925 - val_acc: 0.5192\n",
      "Epoch 72/100\n",
      "13/13 [==============================] - 3s 210ms/step - loss: 0.6868 - acc: 0.5400 - val_loss: 0.6895 - val_acc: 0.5192\n",
      "Epoch 73/100\n",
      "13/13 [==============================] - 3s 207ms/step - loss: 0.6696 - acc: 0.5400 - val_loss: 0.6955 - val_acc: 0.5000\n",
      "Epoch 74/100\n",
      "13/13 [==============================] - 3s 216ms/step - loss: 0.6667 - acc: 0.5350 - val_loss: 0.6921 - val_acc: 0.5577\n",
      "Epoch 75/100\n",
      "13/13 [==============================] - 3s 195ms/step - loss: 0.6598 - acc: 0.5600 - val_loss: 0.6927 - val_acc: 0.5192\n",
      "Epoch 76/100\n",
      "13/13 [==============================] - 3s 215ms/step - loss: 0.6612 - acc: 0.5600 - val_loss: 0.6835 - val_acc: 0.5577\n",
      "Epoch 77/100\n",
      "13/13 [==============================] - 3s 209ms/step - loss: 0.6717 - acc: 0.6200 - val_loss: 0.6861 - val_acc: 0.5385\n",
      "Epoch 78/100\n",
      "13/13 [==============================] - 3s 210ms/step - loss: 0.6610 - acc: 0.5800 - val_loss: 0.6874 - val_acc: 0.5769\n",
      "Epoch 79/100\n",
      "13/13 [==============================] - 3s 217ms/step - loss: 0.6519 - acc: 0.5500 - val_loss: 0.6875 - val_acc: 0.4808\n",
      "Epoch 80/100\n",
      "13/13 [==============================] - 3s 206ms/step - loss: 0.6835 - acc: 0.5150 - val_loss: 0.6931 - val_acc: 0.5577\n",
      "Epoch 81/100\n",
      "13/13 [==============================] - 3s 213ms/step - loss: 0.6736 - acc: 0.5900 - val_loss: 0.6822 - val_acc: 0.5769\n",
      "Epoch 82/100\n",
      "13/13 [==============================] - 3s 214ms/step - loss: 0.6721 - acc: 0.5100 - val_loss: 0.6767 - val_acc: 0.5577\n",
      "Epoch 83/100\n",
      "13/13 [==============================] - 3s 206ms/step - loss: 0.6522 - acc: 0.5850 - val_loss: 0.6877 - val_acc: 0.5385\n",
      "Epoch 84/100\n",
      "13/13 [==============================] - 3s 192ms/step - loss: 0.6663 - acc: 0.5400 - val_loss: 0.6875 - val_acc: 0.5192\n",
      "Epoch 85/100\n",
      "13/13 [==============================] - 3s 202ms/step - loss: 0.6634 - acc: 0.5500 - val_loss: 0.6882 - val_acc: 0.5385\n",
      "Epoch 86/100\n",
      "13/13 [==============================] - 3s 201ms/step - loss: 0.6691 - acc: 0.5100 - val_loss: 0.6849 - val_acc: 0.5385\n",
      "Epoch 87/100\n",
      "13/13 [==============================] - 3s 198ms/step - loss: 0.6586 - acc: 0.5450 - val_loss: 0.6798 - val_acc: 0.5385\n",
      "Epoch 88/100\n",
      "13/13 [==============================] - 3s 213ms/step - loss: 0.6697 - acc: 0.5100 - val_loss: 0.6870 - val_acc: 0.5577\n",
      "Epoch 89/100\n",
      "13/13 [==============================] - 3s 200ms/step - loss: 0.6618 - acc: 0.6250 - val_loss: 0.6868 - val_acc: 0.5385\n",
      "Epoch 90/100\n",
      "13/13 [==============================] - 3s 205ms/step - loss: 0.6718 - acc: 0.5600 - val_loss: 0.6965 - val_acc: 0.5000\n",
      "Epoch 91/100\n",
      "13/13 [==============================] - 3s 196ms/step - loss: 0.6655 - acc: 0.5550 - val_loss: 0.6903 - val_acc: 0.5192\n",
      "Epoch 92/100\n",
      "13/13 [==============================] - 3s 208ms/step - loss: 0.6763 - acc: 0.5450 - val_loss: 0.6939 - val_acc: 0.5000\n",
      "Epoch 93/100\n",
      "13/13 [==============================] - 3s 215ms/step - loss: 0.6741 - acc: 0.5450 - val_loss: 0.6927 - val_acc: 0.5000\n",
      "Epoch 94/100\n",
      "13/13 [==============================] - 3s 203ms/step - loss: 0.6767 - acc: 0.5400 - val_loss: 0.6945 - val_acc: 0.5000\n",
      "Epoch 95/100\n",
      "13/13 [==============================] - 3s 206ms/step - loss: 0.6705 - acc: 0.5450 - val_loss: 0.6896 - val_acc: 0.5192\n",
      "Epoch 96/100\n",
      "13/13 [==============================] - 3s 205ms/step - loss: 0.6751 - acc: 0.5350 - val_loss: 0.6912 - val_acc: 0.5192\n",
      "Epoch 97/100\n",
      "13/13 [==============================] - 3s 201ms/step - loss: 0.6620 - acc: 0.5500 - val_loss: 0.7042 - val_acc: 0.5000\n",
      "Epoch 98/100\n",
      "13/13 [==============================] - 3s 216ms/step - loss: 0.6811 - acc: 0.5400 - val_loss: 0.6842 - val_acc: 0.5192\n",
      "Epoch 99/100\n",
      "13/13 [==============================] - 3s 208ms/step - loss: 0.6561 - acc: 0.5600 - val_loss: 0.6872 - val_acc: 0.5000\n",
      "Epoch 100/100\n",
      "13/13 [==============================] - 3s 208ms/step - loss: 0.6666 - acc: 0.5350 - val_loss: 0.6913 - val_acc: 0.5000\n"
     ]
    }
   ],
   "source": [
    "history1 = model1.fit(\n",
    "    train_generator,\n",
    "    epochs=100,\n",
    "    validation_data=test_generator,\n",
    "    steps_per_epoch=len(train_generator)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_history(history):\n",
    "    acc = history.history[\"accuracy\"]\n",
    "    val_acc = history.history[\"val_accuracy\"]\n",
    "    loss = history.history[\"loss\"]\n",
    "    val_loss = history.history[\"val_loss\"]\n",
    "    epochs = range(len(acc))\n",
    "    plt.plot(epochs, acc, 'r', label=\"training accuracy\")\n",
    "    plt.plot(epochs, val_acc, 'g', label=\"validation accuracy\")\n",
    "    plt.legend()\n",
    "    plt.figure()\n",
    "    plt.plot(epochs, loss, 'r', label=\"training loss\")\n",
    "    plt.plot(epochs, val_loss, 'g', label=\"validation loss\")\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAD4CAYAAAD1jb0+AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAAuWElEQVR4nO3deXgUZbr38e+ThYTsgSyEBJKgSEJCCBAQjYgIKuKI4gojgx4Xjr466nFc0DMj6jkzA3McdHAdFxwXUBDFQWUTRBFlEWIgQNgJZE+A7GTP8/7xdEKarIRsJffnuvpKp7q66u7q6l/dXV1drbTWCCGEsB6Hri5ACCFE20iACyGERUmACyGERUmACyGERUmACyGERTl15sz8/Px0WFhYZ85SCCEsb/v27ce11v5nDu/UAA8LC2Pbtm2dOUshhLA8pdTRxobLLhQhhLAoCXAhhLAoCXAhhLCoTt0HLoTofJWVlaSlpVFWVtbVpYgWuLq6EhISgrOzc6vGlwAX4lcuLS0NT09PwsLCUEp1dTmiCVprTpw4QVpaGuHh4a26j+xCEeJXrqysjN69e0t4d3NKKXr37n1W75QkwIU4D0h4W8PZPk8tBrhSylUptVUptUMptVsp9bxteLhSaotS6qBSarFSqkcba27ZV1/BnDkdNnkhhLCi1nTg5cCVWuuhQCwwUSk1GpgLvKS1vhDIA+7psCpXroS//73DJi+E6Dj5+fm8/vrrbbrvpEmTyM/Pb3acZ599lrVr17Zp+mcKCwvj+PHj7TKtztBigGuj2Pavs+2igSuBpbbh7wM3dkSBADg4QHV1h01eCNFxmgvwqqqqZu+7YsUKfHx8mh3nhRdeYMKECW0tz9JatQ9cKeWolEoEcoBvgENAvta6dumnAcFN3HemUmqbUmpbbm5u26p0dISamrbdVwjRpWbNmsWhQ4eIjY3liSee4LvvvmPMmDFMnjyZwYMHA3DjjTcyYsQIoqKieOutt+ruW9sRp6SkEBkZyX333UdUVBRXX301paWlANx1110sXbq0bvzZs2czfPhwhgwZwt69ewHIzc3lqquuIioqinvvvZfQ0NAWO+158+YRHR1NdHQ0L7/8MgAlJSVcd911DB06lOjoaBYvXlz3GAcPHkxMTAyPP/54uy6/5rTqMEKtdTUQq5TyAZYBEa2dgdb6LeAtgLi4uLb9fpt04EK0j0cfhcTE9p1mbCzYAq4xc+bMYdeuXSTa5vvdd9+RkJDArl276g6XW7BgAb169aK0tJSRI0dy880307t3b7vpHDhwgI8//pi3336b2267jc8++4zp06c3mJ+fnx8JCQm8/vrrvPjii7zzzjs8//zzXHnllTz99NOsWrWKd999t9mHtH37dt577z22bNmC1pqLL76YsWPHcvjwYfr27cvXX38NQEFBASdOnGDZsmXs3bsXpVSLu3za01kdhaK1zgfWA5cAPkqp2g1ACJDevqXV4+goAS7Er8ioUaPsjnWeP38+Q4cOZfTo0aSmpnLgwIEG9wkPDyc2NhaAESNGkJKS0ui0b7rppgbjbNy4kalTpwIwceJEfH19m61v48aNTJkyBXd3dzw8PLjpppv44YcfGDJkCN988w1PPfUUP/zwA97e3nh7e+Pq6so999zD559/jpub21kujbZrsQNXSvkDlVrrfKVUT+AqzAeY64FbgE+AO4F/d1iVsgtFiPbRTKfcmdzd3euuf/fdd6xdu5ZNmzbh5ubGFVdc0eix0C4uLnXXHR0d63ahNDWeo6Nji/vYz9ZFF11EQkICK1as4I9//CPjx4/n2WefZevWraxbt46lS5fy6quv8u2337brfJvSmg48CFivlNoJ/Ax8o7X+CngKeEwpdRDoDTT/nuScqpRdKEJYlaenJ0VFRU3eXlBQgK+vL25ubuzdu5fNmze3ew3x8fEsWbIEgDVr1pCXl9fs+GPGjOGLL77g1KlTlJSUsGzZMsaMGUNGRgZubm5Mnz6dJ554goSEBIqLiykoKGDSpEm89NJL7Nixo93rb0qLHbjWeicwrJHhh4FRHVFUA9KBC2FZvXv3Jj4+nujoaK699lquu+46u9snTpzIm2++SWRkJIMGDWL06NHtXsPs2bOZNm0aH374IZdccgl9+vTB09OzyfGHDx/OXXfdxahRJuLuvfdehg0bxurVq3niiSdwcHDA2dmZN954g6KiIm644QbKysrQWjNv3rx2r78pSuu2fa7YFnFxcbpNP+gweza88IIJcflGmRBnJTk5mcjIyK4uo0uVl5fj6OiIk5MTmzZt4oEHHqj7ULW7aez5Ukpt11rHnTmuNU5m5eho/motAS6EOGvHjh3jtttuo6amhh49evD22293dUntwhoB7mDbVV9dffq6EEK00sCBA/nll1+6uox2Z400rO3AZT+4EELUsUaA1+/AhRBCAFYJ8NoOXAJcCCHqWCvAZReKEELUsUaAyy4UIc4rHh4eAGRkZHDLLbc0Os4VV1xBS4clv/zyy5w6daru/9acnrY1nnvuOV588cVzns65skaASwcuxHmpb9++dWcabIszA7w1p6e1EmsEuHTgQljWrFmzeO211+r+r+1ei4uLGT9+fN2pX//974anU0pJSSE6OhqA0tJSpk6dSmRkJFOmTLE7F8oDDzxAXFwcUVFRzJ49GzAnyMrIyGDcuHGMGzcOsP/BhsZOF9vcaWubkpiYyOjRo4mJiWHKlCl1X9OfP39+3Slma0+k9f333xMbG0tsbCzDhg1r9hQDrWGN48ClAxeiXTy66lESsxLbdZqxfWJ5eeLLTd5+++238+ijj/Lggw8CsGTJElavXo2rqyvLli3Dy8uL48ePM3r0aCZPntzk70K+8cYbuLm5kZyczM6dOxk+fHjdbX/+85/p1asX1dXVjB8/np07d/Lwww8zb9481q9fj5+fn920mjpdrK+vb6tPW1trxowZvPLKK4wdO5Znn32W559/npdffpk5c+Zw5MgRXFxc6nbbvPjii7z22mvEx8dTXFyMq6trK5dy46QDF0J0qGHDhpGTk0NGRgY7duzA19eXfv36obXmmWeeISYmhgkTJpCenk52dnaT09mwYUNdkMbExBATE1N325IlSxg+fDjDhg1j9+7d7Nmzp9mamjpdLLT+tLVgTsSVn5/P2LFjAbjzzjvZsGFDXY133HEHH330EU5OpleOj4/nscceY/78+eTn59cNbyvpwIU4jzTXKXekW2+9laVLl5KVlcXtt98OwMKFC8nNzWX79u04OzsTFhbW6GlkW3LkyBFefPFFfv75Z3x9fbnrrrvaNJ1arT1tbUu+/vprNmzYwJdffsmf//xnkpKSmDVrFtdddx0rVqwgPj6e1atXExHR6t/HaUA6cCFEh7v99tv55JNPWLp0KbfeeitguteAgACcnZ1Zv349R48ebXYal19+OYsWLQJg165d7Ny5E4DCwkLc3d3x9vYmOzublStX1t2nqVPZNnW62LPl7e2Nr69vXff+4YcfMnbsWGpqakhNTWXcuHHMnTuXgoICiouLOXToEEOGDOGpp55i5MiRdT/51lbW6sAlwIWwpKioKIqKiggODiYoKAiAO+64g+uvv54hQ4YQFxfXYif6wAMP8B//8R9ERkYSGRnJiBEjABg6dCjDhg0jIiKCfv36ER8fX3efmTNnMnHiRPr27cv69evrhjd1utjmdpc05f333+f+++/n1KlTDBgwgPfee4/q6mqmT59OQUEBWmsefvhhfHx8+NOf/sT69etxcHAgKiqKa6+99qznV581Tie7cCFMnw779sFFF7V/YUL8isnpZK3lbE4na41dKNKBCyFEA9YKcPkQUwgh6lgjwOVDTCHOSWfuKhVtd7bPkzUCXDpwIdrM1dWVEydOSIh3c1prTpw4cVZf7rHGUSjSgQvRZiEhIaSlpZGbm9vVpYgWuLq6EhIS0urxrRHg0oEL0WbOzs6Eh4d3dRmiA1hjF4p04EII0YA1AlwOIxRCiAZaDHClVD+l1Hql1B6l1G6l1CO24c8ppdKVUom2y6SOq9JWpuxCEUKIOq3ZB14F/EFrnaCU8gS2K6W+sd32kta643+WQjpwIYRooMUA11pnApm260VKqWQguKMLsyMfYgohRANntQ9cKRUGDAO22AY9pJTaqZRaoJTybeI+M5VS25RS29p8GJN8iCmEEA20OsCVUh7AZ8CjWutC4A3gAiAW06H/vbH7aa3f0lrHaa3j/P3921aldOBCCNFAqwJcKeWMCe+FWuvPAbTW2Vrraq11DfA2MKrjqpQOXAghztSao1AU8C6QrLWeV294UL3RpgC72r88G+nAhRCigdYchRIP/A5IUkol2oY9A0xTSsUCGkgB/rMD6jOkAxdCiAZacxTKRqCxn4le0f7lNEE6cCGEaMAa38SUDlwIIRqwRoDLF3mEEKIBawW47EIRQog61ghw2YUihBANWCPApQMXQogGrBHg0oELIUQD1ghw6cCFEKIBawS4dOBCCNGANQJcOnAhhGjAGgEuHbgQQjRgjQCXL/IIIUQD1ghw+U1MIYRowBoBLh24EEI0YK0Alw5cCCHqWCPA5UNMIYRowBoBLh24EEI0YI0Alw5cCCEasEaASwcuhBANWCPAle0X3aQDF0KIOtYIcDBduAS4EELUsU6AOzjILhQhhKjHOgEuHbgQQtixVoBLBy6EEHVaDHClVD+l1Hql1B6l1G6l1CO24b2UUt8opQ7Y/vp2bKUO0oELIUQ9renAq4A/aK0HA6OBB5VSg4FZwDqt9UBgne3/jiMduBBC2GkxwLXWmVrrBNv1IiAZCAZuAN63jfY+cGMH1WhIBy6EEHbOah+4UioMGAZsAQK11pm2m7KAwCbuM1MptU0ptS03N7ftlUoHLoQQdlod4EopD+Az4FGtdWH927TWGtCN3U9r/ZbWOk5rHefv738OlUoHLoQQ9bUqwJVSzpjwXqi1/tw2OFspFWS7PQjI6ZgSbeQwQiGEsNOao1AU8C6QrLWeV++m5cCdtut3Av9u//LqkS/yCCGEHadWjBMP/A5IUkol2oY9A8wBliil7gGOArd1SIW1pAMXQgg7LQa41nojoJq4eXz7ltMM+RBTCCHsWOebmPIhphBC2LFOgEsHLoQQdqwT4NKBCyGEHesEuHTgQghhxzoBLh24EELYsU6Ay2GEQghhxzoBLl/kEUIIO9YJcOnAhRDCjrUCXDpwIYSoY50Alw8xhRDCjnUCXDpwIYSwY50Alw5cCCHsWCfApQMXQgg71glw6cCFEMKOdQJcOnAhhLBjnQCXDlwIIexYJ8DlizxCCGHHOgEuX6UXQgg71glw6cCFEMKOtQJcOnAhhKhjnQCXDzGFEMKOdQJcOnAhhLBjnQCXDlwIIexYJ8ClAxdCCDstBrhSaoFSKkcptavesOeUUulKqUTbZVLHlol04EIIcYbWdOD/AiY2MvwlrXWs7bKifctqhBxGKIQQdloMcK31BuBkJ9TSPPkijxBC2DmXfeAPKaV22nax+DY1klJqplJqm1JqW25ubtvnJh24EELYaWuAvwFcAMQCmcDfmxpRa/2W1jpOax3n7+/fxtkhH2IKIcQZ2hTgWutsrXW11roGeBsY1b5lNUI+xBRCCDttCnClVFC9f6cAu5oat91IBy6EEHacWhpBKfUxcAXgp5RKA2YDVyilYgENpAD/2XEl2kgHLoQQdloMcK31tEYGv9sBtTRPOnAhhLBjnW9iSgcuhBB2rBPgchihEELYsU6Ayxd5hBDCjnUC3NHR/JUQF0IIQAJcCCEsyzoB7mArVfaDCyEEYKUAlw5cCCHsWCfApQMXQgg71glw6cCFEMKOdQJcOnAhhLBjnQCv7cAlwIUQArBSgNd24LILRQghACsFuHTgQghhxzoBLh24EELYsU6ASwcuhBB2rBfg0oELIQRgpQCXwwiFEMKOdQJcOnAhhLBjnQCXDlwIIexYJ8DlQ0whhLBjnQCXwwiFEMKOdQJcOnAhhLBjnQCXDlwIIexYJ8ClAxdCCDstBrhSaoFSKkcptavesF5KqW+UUgdsf307tkzkMEIhhDhDazrwfwETzxg2C1intR4IrLP937HkMEIhhLDTYoBrrTcAJ88YfAPwvu36+8CN7VtWI6QDF0IIO23dBx6otc60Xc8CApsaUSk1Uym1TSm1LTc3t42zQzpwIYQ4wzl/iKm11oBu5va3tNZxWus4f3//ts9IOnAhhLDT1gDPVkoFAdj+5rRfSU2QDlwIIey0NcCXA3fart8J/Lt9ymmGHEYohBB2WnMY4cfAJmCQUipNKXUPMAe4Sil1AJhg+79jyRd5hBDCjlNLI2itpzVx0/h2rqV50oELIYQd630TUzpwIYQArBTg8iGmEELYsU6ASwcuhBB2rBPg0oELIYQd6wS4dOBCCGHHOgEuHbgQQtixToDLYYRCCGHHOgEuX+QRQgg71glw6cCFEMKO9QJcOnAhhACsFODyIaYQQtixToBLBy6EEHasE+DSgQshhB3rBLh04EIIYcc6AV7bgVdVdW0dQgjRTVgnwD08TIgXFHR1JUII0S1YJ8AdHcHPD7Kzu7oSIYToFqwT4AABAZDT8b+fLIQQVmCtAA8MlA5cCCFsrBXg0oELIUQdCXAhhLAoawV4YCAUFUFpaVdXIoQQXc5aAR4QYP5KFy6EEDidy52VUilAEVANVGmt49qjqCYFBpq/2dkQGtqhsxJCiO7unALcZpzW+ng7TKdl0oELIUQda+1Cqd+BCyHEee5cA1wDa5RS25VSMxsbQSk1Uym1TSm1LTc399zm5u9v/to68KziLBYlLTq3aQohhEWda4BfprUeDlwLPKiUuvzMEbTWb2mt47TWcf61AdxWbm7mnCi2AJ+/ZT53fH4HheWF5zZdIYSwoHMKcK11uu1vDrAMGNUeRTWr3rcxd+XsAiCvNK/DZyuEEN1NmwNcKeWulPKsvQ5cDexqr8IaU1pZig7wr+vAd+fuBiCvTAJcCHH+OZcOPBDYqJTaAWwFvtZar2qfshpKzEok4MUA3oksg+xsSipKOJJ3BJAOXAhxfmrzYYRa68PA0HaspUknS08yZfEUiiuKWRpwnPtyKkg+noxGA9KBCyHOT5Y4jPCRVY+QUZTBhAET+M41k5L8HHanJdTdLh24EOJ81B5f5Olwc8bP4ebIm/Hs4cnaw2v5Ngx27fsBB+VAja6RDlwIcV6yRIAHewUT7BVMeVU5Hk7urBxYQkrGDqIDotmds1s6cCHEeckSu1BquTi5MH7AeD6Jhh9L9xEdEI2Pq4904EKI85KlAhzgD5c+TkSZB45VNVxzwTUS4EKI85blAnxM6Bh+Kr6dk296MyPdD9/U4+SfkgAXQpx/LBfgAMTEwIkTcO+9+GYXkJef2dUVCSFEp7NugANkZuJbCnlFcnpZIcT5x5oBPmSI+RsXh2+lI3nlBV1bjxBCdAFrBnjv3vDSS7BgAb7egeRRhta6q6sSQohOZYnjwBv16KMA+AaEUuWQQUl5ER6uXl1bkxBCdCJrduD1+PYbCEDe3sSuLUQIITqZ9QP8wmgA0hK/Z/XB1bIrRQhx3vgVBLj5QHP2T39h4sKJLE762O7246eOM2vtLE5VnuqK8oQQosNYP8A9zS/Vr+1bBsCDn91NVtHp48Kf++455v44l5UHVnZJfUII0VGsH+CuvgBoBTMqBlNSU85vXx5DeVU5R/OP8tb2twD4MfXHrixTCCHanXWPQrHx7elbd/3J33/ChD/dy4yQrUx+eRQlvTxRShHhFyEBLoT41bF8gHu5eKFQhPuGMzgwmqhXvif37kieunAnPpU+zBk/h5ySHF7c9CKnKk/h5uzW1SULIUS7sPwuFAflwCC/QUwfMh2lFLi68tj8nyl5P5jc9/z5r+3OxL+2nKqaKn5O/7mryxVCiHZj+QAHSHogidlXzD49wM+PHh8ugkOH4Pe/59LVewD48djGLqrw7NTomq4uwc6pylMs+GUBJRUlXV2KEO1Ca93tXmdt8asIcCcHJxzUGQ/l8sth8WL49FN6/eUlInPh6y0fdvvjxAvLC4l4NYJpn02jorqi0+efWZTJ/C3z+csPf+GLvV9QWlnKXV/cxT3L7+GRVY+0aZqpBaldEv6HTh7iiTVPsDtnd6fNc1nyMi559xJ2Zu9scdy1h9fy2OrHSMhMOOv1UmvNxmMbeWz1Y0z8aCLjPxjPptRNbS27Vapqqvh6/9eUV5U3OU6NruHdhHc5mn+0Q2up9dX+r7j6w6vxnuPNHZ/fwa6cXdy3/D7GvT+OCR9MYPb62Ty04iGu+egaMm1Hp32X8h2DXx/Mpe9eavlf81KdGWhxcXF627ZtnTa/OlVVvHFrOP8vNo33Lv4rFw6+jN05u1FK8a/Ef6HRvHP9O/i7+1Oja+jj0afza7R5dNWjzN8yH41m0sBJvDv53Qb1pBemk5STRGF5IV4uXlwScgnert7NTresqoy0wjR25+xm7eG1pBelMz1mOldfcDW7cnZxz/J72JO7p8H93J3dKaksYVifYfyS9QvvXP8OY8PGMsB3QN1Gs6yqjKLyIvzd/Rvc/7uU77h24bX08+rHP3/zT5KPJzMiaAQXh1zcquVRUFZAta6mV89eJGQmsCNrB7cMvgVPF8+6cYrKi0jMSiSnJIeogCgi/CI4cOIA494fR3pROgrFmNAxxATE4NHDg+TjyezM3sl9w+/j8Usfx9nRmdLKUvaf2E9ZVRmBHoGEeIXg5NDwI6KK6gqSspPwd/fHy8WLj5M+JtQnlPHh43nh+xf4y8a/ABDmE8byqcvJLM4k2DOYgb0H0sOxB+mF6ZRVlVFRXcGod0ZRXFEMQH/v/owKHoW7sztXhl/J1OipaK353w3/y+d7P+fdye8yOmQ01TXV5Jfl8+CKB1m8ezE9HHsQExhDZlEmJ0pPsGDyAm6Pvp3s4mwyijIY5DeI/LJ8juQd4Uj+EQ7nHaZG13Dr4FvxdPFEoQj1Ca17fIXlhfyc/jNHC44S2yeWndk7WX1oNS9c8QLvJb7HXzf+lZsib2LJLUtwdHAEzIZy3ZF1XBx8MQt+WcD8rfO5qPdFbL5ns91BBo0pKi/i1a2vUlVTxc2Db8bZwZldObtIzErksv6XMS58nN3zsPf4Xl74/gUSMhPo7dabn1J/YoDvAEYFj2LJ7iXU6BpcnVwZ2XckJZUlJGYl4urkSlVNFePDxzNhwAT+sOYPhHqHklGUQVRAFFeGXcnwoOH8dshvzW5YmwMnDrDq4Cr83PxIzEpk74m9uDq5EuIZQkxgDJMHTSarOIvNaZvp49GHi0MuplfPXo0+zl8yf2FI4JBG16nWUEpt11rHNRh+XgQ4UHPwAJf/32C29Kmiql6zPrDXQArLCzlReoKqmip6OPZgzvg5PDL6ERSKpJwk+nr2xc/NDzCBtOLACq4acBVjQsfg6uRKaWUp/7Phf3g74W0ev+RxxoaNZcPRDQzwHUCUfxQOyoFXt77KkfwjjA4ZbYI0dzcZRRk4KkeCPIOI7xcPwNwf53L/iPuJCYzhoZUP4eLoQnz/eBQKpRTJuckcLbDvbpwcnBgRNILogGj6ePQhpySHzWmbCfcNx6OHB2sOreH4qeN14/d06omPqw+ZxaePl+/v3Z8ZMTPwdPHkhkE3EOwVzKbUTby5/U1CvUP56/i/MuqdUXWdpbeLNxF+EVTVVJGUk0RFdUVd6FVWVxLoEUgfjz5sOLqBYM9g8sryyCnJqav3HxP/wdToqfxw9AcWJi0ktTAVN2c3BvsNJqM4g7zSPCqqK9iSvgVH5cjkQZNZtncZVTVVePbwxMfVh8qaSvzc/Nh/Yr/du5Vgz2AyijLo7dabT2/9lHWH1/HN4W/Yk7uHsqoygr2CCfUO5fuj3zPAdwA3DrqRRbsWkVWcZbdMQ71Duaz/ZfTu2ZvFuxdTVFFERXUFZVXmOwfODs5U1lQC0KtnL06WnuTu2Lu5K/YurvrwKsqrT3eqjsqRQI9AMooy6p4DTxdP1s1Yx0+pP7Hm0BqScpIoKCsguyQbVydXnBycKK4oplfPXpyqPEWkXySJWYloNI7KkeeveJ6HL34YTxdPckpyuP7j69mavpV+Xv1IL0pvdBdB7XpUe5tC8WT8k4wOGc3yfcv5eNfHdY+vloNywNvFm7yyPGL7xJKYlci4sHEM6zOMb1O+JTEr0W78KRFT+Gr/V4wKHsVzVzxHH48+FJUXoZTi6/1fs+HYBvp796e0spQNRzeQeyoXhULTMIv83fy5OfJmogOi2ZK+hYVJC+np1JMrw68ktTCVKRFTmHXZLHo49mDD0Q0s37ecRy5+hH7e/QCzgejh2IO3E97m9yt/D8Atg2/h/RvfZ93hddz5xZ2UVpVSVlXGA3EPMHfCXDxdPNmRtYMrP7iSk6Un657rQX6DKK8qJ7UwlbKqMhyVI9W6uq5WVydXrrngGnJKckgrTONU5Sni+saRVZzFjuwdfDXtK6676LoGj7E1zvsAB9i39hPu+nQ6t+xV3BpxMyV9ejFoxmPkFGcz958zCMwoYFMILPc/QYB7AL6uvuw7sQ9nB2fGhJpjy888HNHbxZuiiiJqdA1DA4eyI3tHo/N2dnAm3Dec/Sf24+3iTUxgDCFeIdToGg7nHSYhM4EaXcOwoGGsm7EOH1cfDqTv5IUvH+dgzXF0jx7U6Br6effj8v6XE9snlt5uvcktyWXNoTVsTt/Mntw9HD91HM8enowOGc2hvEMUlhdyzQXXEOkXSR+PPkT4RTAsaBjODs6sPrSandk7qdE1PDjywRa7+KLyIjalbSKtMI3NaZtJyU/BQTkQExhDgHsAiVmJOCgHHB0cySnJIas4C28Xbz666SO01qw6uIoRfUfw1NqnWHNoTd10gzyCGOw/mILyApJzkwn2CibAPQCtNfH94skuyeaDHR8wJXIKvx/1exYlLaKyphJH5Uh2STYRvSMYFz6OQPdANhzdwNaMrUT6RfLbIb/lwl4XQlkZODqCs7Pd4/lq/1fM/XEuG49tJL5fPA+OfBAvFy8yizM5nHeYfSf2sf7IegrLC7nuousI9wnHycGJkX1HklmcybGCY0yLnsZPqT/x6Z5PeWbMM0waOAmAdYfXkXw8mSj/KDKKMth7fC8pBSnEBsbi5ODEmsNreOayZ4jvH29Xk9aaNYfWsPrQasqryvnNRb8hrm8cM7+aSV5pHpf2uxQvFy/Gh49nZPBIu/tWVleyePdiFiYtZGTfkcQExrD/xH58XX0Z4DuAcN9wQr1DKSgv4Iu9X+CgHNiStoV3fnkHADdnN6YPmc7Ng28m1DuUhMyEuncjEz+aiJeLF5vu2cSrW1/lrYS3OJJ3hFHBo7hl8C1cNeAq1h1ZR3FFMc+MeYZFSYt4aMVDFJxxqmeFYkTfEeSU5NDTqSdDAofwxKVP0MejD2sPr8XZwZkBvgMYEjiEtYfXsnj3Yr7c9yWlVaX0dOrJgyMf5Mn4Jxt9t9ccrTV3L78bNyc3/nHtP+w64Rpdw9Nrn+ZvP/0NF0cXBvYeyMGTB/F38+fLaV/ioBzqmqHa8X/J/IXPkz8nwD2Aqy+4mtxTuSxKWsTqQ6sJ8wkj1DsUZwdnNqdvxs3ZjTuH3sm06GktviNpSocEuFJqIvAPwBF4R2s9p7nxuzrAAUhPh8ceg3XrIC8PnJzMxcUFJkxAr1rJZ0N78NnlfmQ7V3BbwDj25ybzQ+k+nJQjk7xG8NAVT7GheBdJBQfIrsjD268vVx/34fJvD7FqVC+OhwdyVZ94jnlpDuYfJj/9IL/xi6dfvyjyfXvi5eKFw8k82LzZzDsggNJenjgFBOHc093UNXs2/POfUFEBDg5w663w5JPmXOgnT0JAANS+3aupMR/YHjiA9vRE9w3CoW8w9OzZ8PFXV5vp1Xur2KTqahN8AOXl8Le/QVoazJgBvr7Qqxf0aWF3U2IizJwJF18M8+aBszNVNVWsPbyWpOwkwnzCmBI5xf6tpdZmGRQXQ79+oBT5Zfl4u3jbvcVtlbQ0GDsWiorg/vvh6acbLJfmpl1VU0VpZandLptfmy1pW6iqqWJE3xG4Ork2Ok5FdUXd7olaNbqm4WdP9ZRWlrL60GoqqyvxdPGkorqC2D6x9Pfuf1b1VddUk3sqF1cnV3xcfc7qvmdjc9pmFiUtIiU/hTCfMP5r9H8R7hveYfM7G+0e4EopR2A/cBWQBvwMTNNaN9yRatMtAry+9HT44x/h+HF44w0ICYGdO+G3v4XUVBMgNTUm7C64wHRyaWlNT8/V1YxTy8XFBOCpeudhCQszoZyR0fg0XFxMWCoFd98NkyfDjz/Cm29CYaGZXnW1qWf4cKiqgg0bzE/MncnHB4KCoG9fcykshNWroX9/uP56E47790NyMnh5wUUXmcu2bfDDD2Z4v34QGgpZWXDggAm/0lIzfaVgwgQYOtQsp717zbhubrBsmXkcOTng7g75+RAVZe4TGGjuN9CcSZLMzNOXY8fgl1/MRgrgmmvg+efNBsPV1Wx4580z85k8GS680CzLlBSzMQwJMZfcXDP89dfNdMeMgZUrYdgwGDcOPvnE1DloEIwcae6fnw8DBsCll8Lgweb/oCDzGF55xTz2kSPNpboajhwx94uIgGuvNRudlBTzt6ICVq2C5cvN9KKizLozbBiMGmWmdfSoWcZ795q/lZXwu9/BlVea53nNGrMOeniAp6d5fFqfvihlppOfb6bl5WXWn7Iycx8fH7PcoqLMY92yxdSVnw+bNpnnYfhwM66rK3h7m+Xh5GSmkZgIBQXmNldXM21nZ1PTsWNw8KCZnpubWU/69TO3rV9vro8caTby3t6na9PaLM+tW039YWFm2LFjkJQEu3aZmqdOBT8/M18PD3NberppPhwczPJxdDTX3d3NY/ngA1i61Ez/ssvgoYfM+u3qah5XTo65T3CwqXPxYvP8zJhhnpclS2D8eJg0yTy3p06Zx3bhhaZRcXQ0dVZXm+WTlGSmFRMDP/1knotLLjGPtaLCZEhKyunL3XdDeNs2CB0R4JcAz2mtr7H9/zSA1vqvTd2n2wV4S8rKzAoQEmJWRDAvlJ9/Nitd7TgpKeZJvvlm01WnpJhA273bBGxMjHkBpqaa293dzfiXXWZeLDk55pKdbTpFLy/4zW8gNvZ0LQUF8N57ZmPj6wvffguHD5uV6ZJLTJcZEWFWzIwMc8nMtP+rlAmafftM6FdVmRdHdLS53759JkQ8PSE+3gRzaqq5b1UVPPWUObpn5Urz+PfsMSt9SoqZ9sCB5nppqQnewEDzWJ991tznlVfMC+HwYbNs6nN0NOMHB5v5RkaaF9Dcuaa2+mJjzQYrNbXl59DPD774wjyer782G+fiYhP+PXrAjh3mcfv7m8vhw/Yb4Vre3uYx5uc3Ph8vL7OBrM/Z2QTC1q1mg9TYOGCCNjLS1JWU1PJjag+enmZ+Z77+e/Y0z1lenlm32qK2yThTjx5mPapp5vC9kBCzjjf2HLTEwcE0JsHBZgNd2wQ0pWdP87pZvdosh8BA8xo8Vy4uJsDrL1sHB/jyS7NxaIOOCPBbgIla63tt//8OuFhr/dAZ480EZgL0799/xNGjnXN4kWhBTY0JQV9fsxEB86I5dsx097W7TlqjtiN0cDjdnbi7N3+f/HzT5YB5d+Dn1/g8MzLMRq+szFz69DEbIa3N/Y8eNS+8Cy808z561HRqgYFmur162e8uSksz44WePvKC4mJTr1JmA7Zli9kQ+fqeHn/6dBN6Bw/C9u0mjMLDzbuZtWtNtxwRYd7B9OpllukFF5hdXZWVpzvV5GRzKS01XWpExOndYVqbDcqOHaamq64yj6G42GzYa0NRqdPjnzplNsJhYWa8igoTTMXFZhnn5pp3lYWF5p1AbSc8eLCZ5t69p5dtbi4kJJjrfn6mKw0MNO+kasepqDDLISjIdLU9e5rppKaai1Lm3U5OjplvQYGZd0GBuTg7m1/UGjnSPN+pqWa9CQoyjYS3txlv7Voz39JS839EhHmOtTbLobrarMPV1Wb6x47B6NFm+deuX1u2mI19ebl53oKCzAYkI8Mss8hI81wlJprXwrhxZmObnGyaEU9P89gOHjSPp7LSrDfOzqbm6Ghz2549ZtmWlZl14+RJs1zCw83zEhZmNipnfAZzNroswOuzXAcuhBDdQFMBfi5f5EkH+tX7P8Q2TAghRCc4lwD/GRiolApXSvUApgLL26csIYQQLWnz2Qi11lVKqYeA1ZjDCBdorTvvO8tCCHGeO6fTyWqtVwAr2qkWIYQQZ+FXcTIrIYQ4H0mACyGERUmACyGERUmACyGERXXq2QiVUrlAW7+K6Qccb3Gsztdd64LuW5vUdXa6a13QfWv7tdUVqrVucArGTg3wc6GU2tbYN5G6WnetC7pvbVLX2emudUH3re18qUt2oQghhEVJgAshhEVZKcDf6uoCmtBd64LuW5vUdXa6a13QfWs7L+qyzD5wIYQQ9qzUgQshhKhHAlwIISzKEgGulJqolNqnlDqolJrVhXX0U0qtV0rtUUrtVko9Yhv+nFIqXSmVaLu07XeTzq22FKVUkm3+22zDeimlvlFKHbD9bdtPYre9pkH1lkmiUqpQKfVoVy0vpdQCpVSOUmpXvWGNLiNlzLetczuVUsM7ua7/U0rttc17mVLKxzY8TClVWm/ZvdnJdTX53CmlnrYtr31KqWs6ua7F9WpKUUol2oZ35vJqKh86bh3TWnfrC+ZUtYeAAUAPYAcwuItqCQKG2657Yn7UeTDwHPB4Fy+nFMDvjGF/A2bZrs8C5nbx85gFhHbV8gIuB4YDu1paRsAkYCWggNHAlk6u62rAyXZ9br26wuqP1wXLq9HnzvY62AG4AOG216xjZ9V1xu1/B57tguXVVD502DpmhQ58FHBQa31Ya10BfALc0BWFaK0ztdYJtutFQDIQ3BW1tNINwPu26+8DN3ZdKYwHDmmtu+xHUbXWG4Azf+m2qWV0A/CBNjYDPkqpoM6qS2u9RmtdZft3M+YXrzpVE8urKTcAn2ity7XWR4CDmNdup9allFLAbcDHHTHv5jSTDx22jlkhwIOB+j8/nkY3CE2lVBgwDNhiG/SQ7W3Qgs7eVWGjgTVKqe3K/JA0QKDWOtN2PQsI7IK6ak3F/kXV1curVlPLqDutd3djOrVa4UqpX5RS3yulxnRBPY09d91leY0BsrXWB+oN6/TldUY+dNg6ZoUA73aUUh7AZ8CjWutC4A3gAiAWyMS8hetsl2mthwPXAg8qpS6vf6M279m65JhRZX5ybzLwqW1Qd1heDXTlMmqKUuq/gSpgoW1QJtBfaz0MeAxYpJTy6sSSuuVzV8807BuFTl9ejeRDnfZex6wQ4N3qx5OVUs6YJ2eh1vpzAK11tta6WmtdA7xNB711bI7WOt32NwdYZqshu/Ytme1vTmfXZXMtkKC1zrbV2OXLq56mllGXr3dKqbuA3wB32F742HZRnLBd347Z13xRZ9XUzHPXHZaXE3ATsLh2WGcvr8bygQ5cx6wQ4N3mx5Nt+9feBZK11vPqDa+/32oKsOvM+3ZwXe5KKc/a65gPwHZhltOdttHuBP7dmXXVY9cVdfXyOkNTy2g5MMN2pMBooKDe2+AOp5SaCDwJTNZan6o33F8p5Wi7PgAYCBzuxLqaeu6WA1OVUi5KqXBbXVs7qy6bCcBerXVa7YDOXF5N5QMduY51xqez7fDp7iTMJ7qHgP/uwjouw7z92Qkk2i6TgA+BJNvw5UBQJ9c1AHMEwA5gd+0yAnoD64ADwFqgVxcsM3fgBOBdb1iXLC/MRiQTqMTsb7ynqWWEOTLgNds6lwTEdXJdBzH7R2vXszdt495se44TgQTg+k6uq8nnDvhv2/LaB1zbmXXZhv8LuP+McTtzeTWVDx22jslX6YUQwqKssAtFCCFEIyTAhRDCoiTAhRDCoiTAhRDCoiTAhRDCoiTAhRDCoiTAhRDCov4/tBFPDU9M8eQAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_history(history=history1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_transfer():\n",
    "    pre_trained_model = InceptionV3(\n",
    "        input_shape=(224, 224, 3),\n",
    "        include_top=False,\n",
    "        weights=\"imagenet\"\n",
    "    )\n",
    "\n",
    "    for layer in pre_trained_model.layers:\n",
    "        layer.trainable=False\n",
    "\n",
    "    x = Dropout(0.5)(pre_trained_model.output)\n",
    "    x = Flatten()(x)\n",
    "    x = Dropout(0.25)(x)\n",
    "    x = Dense(256, activation=relu)(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(128, activation=relu)(x)\n",
    "    x = Dense(1, activation=sigmoid)(x)\n",
    "\n",
    "    model = Model(pre_trained_model.input, x)\n",
    "\n",
    "    model.compile(loss=binary_crossentropy, optimizer=Adam(lr=0.001), metrics=[\"accuracy\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 224, 224, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 111, 111, 32  864         ['input_1[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 111, 111, 32  96         ['conv2d_4[0][0]']               \n",
      " alization)                     )                                                                 \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 111, 111, 32  0           ['batch_normalization[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 109, 109, 32  9216        ['activation[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 109, 109, 32  96         ['conv2d_5[0][0]']               \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, 109, 109, 32  0           ['batch_normalization_1[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 109, 109, 64  18432       ['activation_1[0][0]']           \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 109, 109, 64  192        ['conv2d_6[0][0]']               \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " activation_2 (Activation)      (None, 109, 109, 64  0           ['batch_normalization_2[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d_4 (MaxPooling2D)  (None, 54, 54, 64)  0           ['activation_2[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 54, 54, 80)   5120        ['max_pooling2d_4[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 54, 54, 80)  240         ['conv2d_7[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_3 (Activation)      (None, 54, 54, 80)   0           ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, 52, 52, 192)  138240      ['activation_3[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 52, 52, 192)  576        ['conv2d_8[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_4 (Activation)      (None, 52, 52, 192)  0           ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " max_pooling2d_5 (MaxPooling2D)  (None, 25, 25, 192)  0          ['activation_4[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)             (None, 25, 25, 64)   12288       ['max_pooling2d_5[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 25, 25, 64)  192         ['conv2d_12[0][0]']              \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_8 (Activation)      (None, 25, 25, 64)   0           ['batch_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)             (None, 25, 25, 48)   9216        ['max_pooling2d_5[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)             (None, 25, 25, 96)   55296       ['activation_8[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 25, 25, 48)  144         ['conv2d_10[0][0]']              \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_9 (BatchNo  (None, 25, 25, 96)  288         ['conv2d_13[0][0]']              \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_6 (Activation)      (None, 25, 25, 48)   0           ['batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " activation_9 (Activation)      (None, 25, 25, 96)   0           ['batch_normalization_9[0][0]']  \n",
      "                                                                                                  \n",
      " average_pooling2d (AveragePool  (None, 25, 25, 192)  0          ['max_pooling2d_5[0][0]']        \n",
      " ing2D)                                                                                           \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)              (None, 25, 25, 64)   12288       ['max_pooling2d_5[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)             (None, 25, 25, 64)   76800       ['activation_6[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)             (None, 25, 25, 96)   82944       ['activation_9[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_15 (Conv2D)             (None, 25, 25, 32)   6144        ['average_pooling2d[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 25, 25, 64)  192         ['conv2d_9[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 25, 25, 64)  192         ['conv2d_11[0][0]']              \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_10 (BatchN  (None, 25, 25, 96)  288         ['conv2d_14[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_11 (BatchN  (None, 25, 25, 32)  96          ['conv2d_15[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_5 (Activation)      (None, 25, 25, 64)   0           ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " activation_7 (Activation)      (None, 25, 25, 64)   0           ['batch_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " activation_10 (Activation)     (None, 25, 25, 96)   0           ['batch_normalization_10[0][0]'] \n",
      "                                                                                                  \n",
      " activation_11 (Activation)     (None, 25, 25, 32)   0           ['batch_normalization_11[0][0]'] \n",
      "                                                                                                  \n",
      " mixed0 (Concatenate)           (None, 25, 25, 256)  0           ['activation_5[0][0]',           \n",
      "                                                                  'activation_7[0][0]',           \n",
      "                                                                  'activation_10[0][0]',          \n",
      "                                                                  'activation_11[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_19 (Conv2D)             (None, 25, 25, 64)   16384       ['mixed0[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_15 (BatchN  (None, 25, 25, 64)  192         ['conv2d_19[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_15 (Activation)     (None, 25, 25, 64)   0           ['batch_normalization_15[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_17 (Conv2D)             (None, 25, 25, 48)   12288       ['mixed0[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_20 (Conv2D)             (None, 25, 25, 96)   55296       ['activation_15[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_13 (BatchN  (None, 25, 25, 48)  144         ['conv2d_17[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_16 (BatchN  (None, 25, 25, 96)  288         ['conv2d_20[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_13 (Activation)     (None, 25, 25, 48)   0           ['batch_normalization_13[0][0]'] \n",
      "                                                                                                  \n",
      " activation_16 (Activation)     (None, 25, 25, 96)   0           ['batch_normalization_16[0][0]'] \n",
      "                                                                                                  \n",
      " average_pooling2d_1 (AveragePo  (None, 25, 25, 256)  0          ['mixed0[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_16 (Conv2D)             (None, 25, 25, 64)   16384       ['mixed0[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_18 (Conv2D)             (None, 25, 25, 64)   76800       ['activation_13[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_21 (Conv2D)             (None, 25, 25, 96)   82944       ['activation_16[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_22 (Conv2D)             (None, 25, 25, 64)   16384       ['average_pooling2d_1[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_12 (BatchN  (None, 25, 25, 64)  192         ['conv2d_16[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_14 (BatchN  (None, 25, 25, 64)  192         ['conv2d_18[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_17 (BatchN  (None, 25, 25, 96)  288         ['conv2d_21[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_18 (BatchN  (None, 25, 25, 64)  192         ['conv2d_22[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_12 (Activation)     (None, 25, 25, 64)   0           ['batch_normalization_12[0][0]'] \n",
      "                                                                                                  \n",
      " activation_14 (Activation)     (None, 25, 25, 64)   0           ['batch_normalization_14[0][0]'] \n",
      "                                                                                                  \n",
      " activation_17 (Activation)     (None, 25, 25, 96)   0           ['batch_normalization_17[0][0]'] \n",
      "                                                                                                  \n",
      " activation_18 (Activation)     (None, 25, 25, 64)   0           ['batch_normalization_18[0][0]'] \n",
      "                                                                                                  \n",
      " mixed1 (Concatenate)           (None, 25, 25, 288)  0           ['activation_12[0][0]',          \n",
      "                                                                  'activation_14[0][0]',          \n",
      "                                                                  'activation_17[0][0]',          \n",
      "                                                                  'activation_18[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_26 (Conv2D)             (None, 25, 25, 64)   18432       ['mixed1[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_22 (BatchN  (None, 25, 25, 64)  192         ['conv2d_26[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_22 (Activation)     (None, 25, 25, 64)   0           ['batch_normalization_22[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_24 (Conv2D)             (None, 25, 25, 48)   13824       ['mixed1[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_27 (Conv2D)             (None, 25, 25, 96)   55296       ['activation_22[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_20 (BatchN  (None, 25, 25, 48)  144         ['conv2d_24[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_23 (BatchN  (None, 25, 25, 96)  288         ['conv2d_27[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_20 (Activation)     (None, 25, 25, 48)   0           ['batch_normalization_20[0][0]'] \n",
      "                                                                                                  \n",
      " activation_23 (Activation)     (None, 25, 25, 96)   0           ['batch_normalization_23[0][0]'] \n",
      "                                                                                                  \n",
      " average_pooling2d_2 (AveragePo  (None, 25, 25, 288)  0          ['mixed1[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_23 (Conv2D)             (None, 25, 25, 64)   18432       ['mixed1[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_25 (Conv2D)             (None, 25, 25, 64)   76800       ['activation_20[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_28 (Conv2D)             (None, 25, 25, 96)   82944       ['activation_23[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_29 (Conv2D)             (None, 25, 25, 64)   18432       ['average_pooling2d_2[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_19 (BatchN  (None, 25, 25, 64)  192         ['conv2d_23[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_21 (BatchN  (None, 25, 25, 64)  192         ['conv2d_25[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_24 (BatchN  (None, 25, 25, 96)  288         ['conv2d_28[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_25 (BatchN  (None, 25, 25, 64)  192         ['conv2d_29[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_19 (Activation)     (None, 25, 25, 64)   0           ['batch_normalization_19[0][0]'] \n",
      "                                                                                                  \n",
      " activation_21 (Activation)     (None, 25, 25, 64)   0           ['batch_normalization_21[0][0]'] \n",
      "                                                                                                  \n",
      " activation_24 (Activation)     (None, 25, 25, 96)   0           ['batch_normalization_24[0][0]'] \n",
      "                                                                                                  \n",
      " activation_25 (Activation)     (None, 25, 25, 64)   0           ['batch_normalization_25[0][0]'] \n",
      "                                                                                                  \n",
      " mixed2 (Concatenate)           (None, 25, 25, 288)  0           ['activation_19[0][0]',          \n",
      "                                                                  'activation_21[0][0]',          \n",
      "                                                                  'activation_24[0][0]',          \n",
      "                                                                  'activation_25[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_31 (Conv2D)             (None, 25, 25, 64)   18432       ['mixed2[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_27 (BatchN  (None, 25, 25, 64)  192         ['conv2d_31[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_27 (Activation)     (None, 25, 25, 64)   0           ['batch_normalization_27[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_32 (Conv2D)             (None, 25, 25, 96)   55296       ['activation_27[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_28 (BatchN  (None, 25, 25, 96)  288         ['conv2d_32[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_28 (Activation)     (None, 25, 25, 96)   0           ['batch_normalization_28[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_30 (Conv2D)             (None, 12, 12, 384)  995328      ['mixed2[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_33 (Conv2D)             (None, 12, 12, 96)   82944       ['activation_28[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_26 (BatchN  (None, 12, 12, 384)  1152       ['conv2d_30[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_29 (BatchN  (None, 12, 12, 96)  288         ['conv2d_33[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_26 (Activation)     (None, 12, 12, 384)  0           ['batch_normalization_26[0][0]'] \n",
      "                                                                                                  \n",
      " activation_29 (Activation)     (None, 12, 12, 96)   0           ['batch_normalization_29[0][0]'] \n",
      "                                                                                                  \n",
      " max_pooling2d_6 (MaxPooling2D)  (None, 12, 12, 288)  0          ['mixed2[0][0]']                 \n",
      "                                                                                                  \n",
      " mixed3 (Concatenate)           (None, 12, 12, 768)  0           ['activation_26[0][0]',          \n",
      "                                                                  'activation_29[0][0]',          \n",
      "                                                                  'max_pooling2d_6[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_38 (Conv2D)             (None, 12, 12, 128)  98304       ['mixed3[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_34 (BatchN  (None, 12, 12, 128)  384        ['conv2d_38[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_34 (Activation)     (None, 12, 12, 128)  0           ['batch_normalization_34[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_39 (Conv2D)             (None, 12, 12, 128)  114688      ['activation_34[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_35 (BatchN  (None, 12, 12, 128)  384        ['conv2d_39[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_35 (Activation)     (None, 12, 12, 128)  0           ['batch_normalization_35[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_35 (Conv2D)             (None, 12, 12, 128)  98304       ['mixed3[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_40 (Conv2D)             (None, 12, 12, 128)  114688      ['activation_35[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_31 (BatchN  (None, 12, 12, 128)  384        ['conv2d_35[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_36 (BatchN  (None, 12, 12, 128)  384        ['conv2d_40[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_31 (Activation)     (None, 12, 12, 128)  0           ['batch_normalization_31[0][0]'] \n",
      "                                                                                                  \n",
      " activation_36 (Activation)     (None, 12, 12, 128)  0           ['batch_normalization_36[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_36 (Conv2D)             (None, 12, 12, 128)  114688      ['activation_31[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_41 (Conv2D)             (None, 12, 12, 128)  114688      ['activation_36[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_32 (BatchN  (None, 12, 12, 128)  384        ['conv2d_36[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_37 (BatchN  (None, 12, 12, 128)  384        ['conv2d_41[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_32 (Activation)     (None, 12, 12, 128)  0           ['batch_normalization_32[0][0]'] \n",
      "                                                                                                  \n",
      " activation_37 (Activation)     (None, 12, 12, 128)  0           ['batch_normalization_37[0][0]'] \n",
      "                                                                                                  \n",
      " average_pooling2d_3 (AveragePo  (None, 12, 12, 768)  0          ['mixed3[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_34 (Conv2D)             (None, 12, 12, 192)  147456      ['mixed3[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_37 (Conv2D)             (None, 12, 12, 192)  172032      ['activation_32[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_42 (Conv2D)             (None, 12, 12, 192)  172032      ['activation_37[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_43 (Conv2D)             (None, 12, 12, 192)  147456      ['average_pooling2d_3[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_30 (BatchN  (None, 12, 12, 192)  576        ['conv2d_34[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_33 (BatchN  (None, 12, 12, 192)  576        ['conv2d_37[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_38 (BatchN  (None, 12, 12, 192)  576        ['conv2d_42[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_39 (BatchN  (None, 12, 12, 192)  576        ['conv2d_43[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_30 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_30[0][0]'] \n",
      "                                                                                                  \n",
      " activation_33 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_33[0][0]'] \n",
      "                                                                                                  \n",
      " activation_38 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_38[0][0]'] \n",
      "                                                                                                  \n",
      " activation_39 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_39[0][0]'] \n",
      "                                                                                                  \n",
      " mixed4 (Concatenate)           (None, 12, 12, 768)  0           ['activation_30[0][0]',          \n",
      "                                                                  'activation_33[0][0]',          \n",
      "                                                                  'activation_38[0][0]',          \n",
      "                                                                  'activation_39[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_48 (Conv2D)             (None, 12, 12, 160)  122880      ['mixed4[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_44 (BatchN  (None, 12, 12, 160)  480        ['conv2d_48[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_44 (Activation)     (None, 12, 12, 160)  0           ['batch_normalization_44[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_49 (Conv2D)             (None, 12, 12, 160)  179200      ['activation_44[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_45 (BatchN  (None, 12, 12, 160)  480        ['conv2d_49[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_45 (Activation)     (None, 12, 12, 160)  0           ['batch_normalization_45[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_45 (Conv2D)             (None, 12, 12, 160)  122880      ['mixed4[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_50 (Conv2D)             (None, 12, 12, 160)  179200      ['activation_45[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_41 (BatchN  (None, 12, 12, 160)  480        ['conv2d_45[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_46 (BatchN  (None, 12, 12, 160)  480        ['conv2d_50[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_41 (Activation)     (None, 12, 12, 160)  0           ['batch_normalization_41[0][0]'] \n",
      "                                                                                                  \n",
      " activation_46 (Activation)     (None, 12, 12, 160)  0           ['batch_normalization_46[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_46 (Conv2D)             (None, 12, 12, 160)  179200      ['activation_41[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_51 (Conv2D)             (None, 12, 12, 160)  179200      ['activation_46[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_42 (BatchN  (None, 12, 12, 160)  480        ['conv2d_46[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_47 (BatchN  (None, 12, 12, 160)  480        ['conv2d_51[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_42 (Activation)     (None, 12, 12, 160)  0           ['batch_normalization_42[0][0]'] \n",
      "                                                                                                  \n",
      " activation_47 (Activation)     (None, 12, 12, 160)  0           ['batch_normalization_47[0][0]'] \n",
      "                                                                                                  \n",
      " average_pooling2d_4 (AveragePo  (None, 12, 12, 768)  0          ['mixed4[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_44 (Conv2D)             (None, 12, 12, 192)  147456      ['mixed4[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_47 (Conv2D)             (None, 12, 12, 192)  215040      ['activation_42[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_52 (Conv2D)             (None, 12, 12, 192)  215040      ['activation_47[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_53 (Conv2D)             (None, 12, 12, 192)  147456      ['average_pooling2d_4[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_40 (BatchN  (None, 12, 12, 192)  576        ['conv2d_44[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_43 (BatchN  (None, 12, 12, 192)  576        ['conv2d_47[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_48 (BatchN  (None, 12, 12, 192)  576        ['conv2d_52[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_49 (BatchN  (None, 12, 12, 192)  576        ['conv2d_53[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_40 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_40[0][0]'] \n",
      "                                                                                                  \n",
      " activation_43 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_43[0][0]'] \n",
      "                                                                                                  \n",
      " activation_48 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_48[0][0]'] \n",
      "                                                                                                  \n",
      " activation_49 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_49[0][0]'] \n",
      "                                                                                                  \n",
      " mixed5 (Concatenate)           (None, 12, 12, 768)  0           ['activation_40[0][0]',          \n",
      "                                                                  'activation_43[0][0]',          \n",
      "                                                                  'activation_48[0][0]',          \n",
      "                                                                  'activation_49[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_58 (Conv2D)             (None, 12, 12, 160)  122880      ['mixed5[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_54 (BatchN  (None, 12, 12, 160)  480        ['conv2d_58[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_54 (Activation)     (None, 12, 12, 160)  0           ['batch_normalization_54[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_59 (Conv2D)             (None, 12, 12, 160)  179200      ['activation_54[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_55 (BatchN  (None, 12, 12, 160)  480        ['conv2d_59[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_55 (Activation)     (None, 12, 12, 160)  0           ['batch_normalization_55[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_55 (Conv2D)             (None, 12, 12, 160)  122880      ['mixed5[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_60 (Conv2D)             (None, 12, 12, 160)  179200      ['activation_55[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_51 (BatchN  (None, 12, 12, 160)  480        ['conv2d_55[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_56 (BatchN  (None, 12, 12, 160)  480        ['conv2d_60[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_51 (Activation)     (None, 12, 12, 160)  0           ['batch_normalization_51[0][0]'] \n",
      "                                                                                                  \n",
      " activation_56 (Activation)     (None, 12, 12, 160)  0           ['batch_normalization_56[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_56 (Conv2D)             (None, 12, 12, 160)  179200      ['activation_51[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_61 (Conv2D)             (None, 12, 12, 160)  179200      ['activation_56[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_52 (BatchN  (None, 12, 12, 160)  480        ['conv2d_56[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_57 (BatchN  (None, 12, 12, 160)  480        ['conv2d_61[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_52 (Activation)     (None, 12, 12, 160)  0           ['batch_normalization_52[0][0]'] \n",
      "                                                                                                  \n",
      " activation_57 (Activation)     (None, 12, 12, 160)  0           ['batch_normalization_57[0][0]'] \n",
      "                                                                                                  \n",
      " average_pooling2d_5 (AveragePo  (None, 12, 12, 768)  0          ['mixed5[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_54 (Conv2D)             (None, 12, 12, 192)  147456      ['mixed5[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_57 (Conv2D)             (None, 12, 12, 192)  215040      ['activation_52[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_62 (Conv2D)             (None, 12, 12, 192)  215040      ['activation_57[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_63 (Conv2D)             (None, 12, 12, 192)  147456      ['average_pooling2d_5[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_50 (BatchN  (None, 12, 12, 192)  576        ['conv2d_54[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_53 (BatchN  (None, 12, 12, 192)  576        ['conv2d_57[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_58 (BatchN  (None, 12, 12, 192)  576        ['conv2d_62[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_59 (BatchN  (None, 12, 12, 192)  576        ['conv2d_63[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_50 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_50[0][0]'] \n",
      "                                                                                                  \n",
      " activation_53 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_53[0][0]'] \n",
      "                                                                                                  \n",
      " activation_58 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_58[0][0]'] \n",
      "                                                                                                  \n",
      " activation_59 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_59[0][0]'] \n",
      "                                                                                                  \n",
      " mixed6 (Concatenate)           (None, 12, 12, 768)  0           ['activation_50[0][0]',          \n",
      "                                                                  'activation_53[0][0]',          \n",
      "                                                                  'activation_58[0][0]',          \n",
      "                                                                  'activation_59[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_68 (Conv2D)             (None, 12, 12, 192)  147456      ['mixed6[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_64 (BatchN  (None, 12, 12, 192)  576        ['conv2d_68[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_64 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_64[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_69 (Conv2D)             (None, 12, 12, 192)  258048      ['activation_64[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_65 (BatchN  (None, 12, 12, 192)  576        ['conv2d_69[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_65 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_65[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_65 (Conv2D)             (None, 12, 12, 192)  147456      ['mixed6[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_70 (Conv2D)             (None, 12, 12, 192)  258048      ['activation_65[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_61 (BatchN  (None, 12, 12, 192)  576        ['conv2d_65[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_66 (BatchN  (None, 12, 12, 192)  576        ['conv2d_70[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_61 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_61[0][0]'] \n",
      "                                                                                                  \n",
      " activation_66 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_66[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_66 (Conv2D)             (None, 12, 12, 192)  258048      ['activation_61[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_71 (Conv2D)             (None, 12, 12, 192)  258048      ['activation_66[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_62 (BatchN  (None, 12, 12, 192)  576        ['conv2d_66[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_67 (BatchN  (None, 12, 12, 192)  576        ['conv2d_71[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_62 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_62[0][0]'] \n",
      "                                                                                                  \n",
      " activation_67 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_67[0][0]'] \n",
      "                                                                                                  \n",
      " average_pooling2d_6 (AveragePo  (None, 12, 12, 768)  0          ['mixed6[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_64 (Conv2D)             (None, 12, 12, 192)  147456      ['mixed6[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_67 (Conv2D)             (None, 12, 12, 192)  258048      ['activation_62[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_72 (Conv2D)             (None, 12, 12, 192)  258048      ['activation_67[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_73 (Conv2D)             (None, 12, 12, 192)  147456      ['average_pooling2d_6[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_60 (BatchN  (None, 12, 12, 192)  576        ['conv2d_64[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_63 (BatchN  (None, 12, 12, 192)  576        ['conv2d_67[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_68 (BatchN  (None, 12, 12, 192)  576        ['conv2d_72[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_69 (BatchN  (None, 12, 12, 192)  576        ['conv2d_73[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_60 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_60[0][0]'] \n",
      "                                                                                                  \n",
      " activation_63 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_63[0][0]'] \n",
      "                                                                                                  \n",
      " activation_68 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_68[0][0]'] \n",
      "                                                                                                  \n",
      " activation_69 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_69[0][0]'] \n",
      "                                                                                                  \n",
      " mixed7 (Concatenate)           (None, 12, 12, 768)  0           ['activation_60[0][0]',          \n",
      "                                                                  'activation_63[0][0]',          \n",
      "                                                                  'activation_68[0][0]',          \n",
      "                                                                  'activation_69[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_76 (Conv2D)             (None, 12, 12, 192)  147456      ['mixed7[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_72 (BatchN  (None, 12, 12, 192)  576        ['conv2d_76[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_72 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_72[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_77 (Conv2D)             (None, 12, 12, 192)  258048      ['activation_72[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_73 (BatchN  (None, 12, 12, 192)  576        ['conv2d_77[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_73 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_73[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_74 (Conv2D)             (None, 12, 12, 192)  147456      ['mixed7[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_78 (Conv2D)             (None, 12, 12, 192)  258048      ['activation_73[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_70 (BatchN  (None, 12, 12, 192)  576        ['conv2d_74[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_74 (BatchN  (None, 12, 12, 192)  576        ['conv2d_78[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_70 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_70[0][0]'] \n",
      "                                                                                                  \n",
      " activation_74 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_74[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_75 (Conv2D)             (None, 5, 5, 320)    552960      ['activation_70[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_79 (Conv2D)             (None, 5, 5, 192)    331776      ['activation_74[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_71 (BatchN  (None, 5, 5, 320)   960         ['conv2d_75[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_75 (BatchN  (None, 5, 5, 192)   576         ['conv2d_79[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_71 (Activation)     (None, 5, 5, 320)    0           ['batch_normalization_71[0][0]'] \n",
      "                                                                                                  \n",
      " activation_75 (Activation)     (None, 5, 5, 192)    0           ['batch_normalization_75[0][0]'] \n",
      "                                                                                                  \n",
      " max_pooling2d_7 (MaxPooling2D)  (None, 5, 5, 768)   0           ['mixed7[0][0]']                 \n",
      "                                                                                                  \n",
      " mixed8 (Concatenate)           (None, 5, 5, 1280)   0           ['activation_71[0][0]',          \n",
      "                                                                  'activation_75[0][0]',          \n",
      "                                                                  'max_pooling2d_7[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_84 (Conv2D)             (None, 5, 5, 448)    573440      ['mixed8[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_80 (BatchN  (None, 5, 5, 448)   1344        ['conv2d_84[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_80 (Activation)     (None, 5, 5, 448)    0           ['batch_normalization_80[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_81 (Conv2D)             (None, 5, 5, 384)    491520      ['mixed8[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_85 (Conv2D)             (None, 5, 5, 384)    1548288     ['activation_80[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_77 (BatchN  (None, 5, 5, 384)   1152        ['conv2d_81[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_81 (BatchN  (None, 5, 5, 384)   1152        ['conv2d_85[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_77 (Activation)     (None, 5, 5, 384)    0           ['batch_normalization_77[0][0]'] \n",
      "                                                                                                  \n",
      " activation_81 (Activation)     (None, 5, 5, 384)    0           ['batch_normalization_81[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_82 (Conv2D)             (None, 5, 5, 384)    442368      ['activation_77[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_83 (Conv2D)             (None, 5, 5, 384)    442368      ['activation_77[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_86 (Conv2D)             (None, 5, 5, 384)    442368      ['activation_81[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_87 (Conv2D)             (None, 5, 5, 384)    442368      ['activation_81[0][0]']          \n",
      "                                                                                                  \n",
      " average_pooling2d_7 (AveragePo  (None, 5, 5, 1280)  0           ['mixed8[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_80 (Conv2D)             (None, 5, 5, 320)    409600      ['mixed8[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_78 (BatchN  (None, 5, 5, 384)   1152        ['conv2d_82[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_79 (BatchN  (None, 5, 5, 384)   1152        ['conv2d_83[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_82 (BatchN  (None, 5, 5, 384)   1152        ['conv2d_86[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_83 (BatchN  (None, 5, 5, 384)   1152        ['conv2d_87[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_88 (Conv2D)             (None, 5, 5, 192)    245760      ['average_pooling2d_7[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_76 (BatchN  (None, 5, 5, 320)   960         ['conv2d_80[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_78 (Activation)     (None, 5, 5, 384)    0           ['batch_normalization_78[0][0]'] \n",
      "                                                                                                  \n",
      " activation_79 (Activation)     (None, 5, 5, 384)    0           ['batch_normalization_79[0][0]'] \n",
      "                                                                                                  \n",
      " activation_82 (Activation)     (None, 5, 5, 384)    0           ['batch_normalization_82[0][0]'] \n",
      "                                                                                                  \n",
      " activation_83 (Activation)     (None, 5, 5, 384)    0           ['batch_normalization_83[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_84 (BatchN  (None, 5, 5, 192)   576         ['conv2d_88[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_76 (Activation)     (None, 5, 5, 320)    0           ['batch_normalization_76[0][0]'] \n",
      "                                                                                                  \n",
      " mixed9_0 (Concatenate)         (None, 5, 5, 768)    0           ['activation_78[0][0]',          \n",
      "                                                                  'activation_79[0][0]']          \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 5, 5, 768)    0           ['activation_82[0][0]',          \n",
      "                                                                  'activation_83[0][0]']          \n",
      "                                                                                                  \n",
      " activation_84 (Activation)     (None, 5, 5, 192)    0           ['batch_normalization_84[0][0]'] \n",
      "                                                                                                  \n",
      " mixed9 (Concatenate)           (None, 5, 5, 2048)   0           ['activation_76[0][0]',          \n",
      "                                                                  'mixed9_0[0][0]',               \n",
      "                                                                  'concatenate[0][0]',            \n",
      "                                                                  'activation_84[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_93 (Conv2D)             (None, 5, 5, 448)    917504      ['mixed9[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_89 (BatchN  (None, 5, 5, 448)   1344        ['conv2d_93[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_89 (Activation)     (None, 5, 5, 448)    0           ['batch_normalization_89[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_90 (Conv2D)             (None, 5, 5, 384)    786432      ['mixed9[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_94 (Conv2D)             (None, 5, 5, 384)    1548288     ['activation_89[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_86 (BatchN  (None, 5, 5, 384)   1152        ['conv2d_90[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_90 (BatchN  (None, 5, 5, 384)   1152        ['conv2d_94[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_86 (Activation)     (None, 5, 5, 384)    0           ['batch_normalization_86[0][0]'] \n",
      "                                                                                                  \n",
      " activation_90 (Activation)     (None, 5, 5, 384)    0           ['batch_normalization_90[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_91 (Conv2D)             (None, 5, 5, 384)    442368      ['activation_86[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_92 (Conv2D)             (None, 5, 5, 384)    442368      ['activation_86[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_95 (Conv2D)             (None, 5, 5, 384)    442368      ['activation_90[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_96 (Conv2D)             (None, 5, 5, 384)    442368      ['activation_90[0][0]']          \n",
      "                                                                                                  \n",
      " average_pooling2d_8 (AveragePo  (None, 5, 5, 2048)  0           ['mixed9[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_89 (Conv2D)             (None, 5, 5, 320)    655360      ['mixed9[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_87 (BatchN  (None, 5, 5, 384)   1152        ['conv2d_91[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_88 (BatchN  (None, 5, 5, 384)   1152        ['conv2d_92[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_91 (BatchN  (None, 5, 5, 384)   1152        ['conv2d_95[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_92 (BatchN  (None, 5, 5, 384)   1152        ['conv2d_96[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_97 (Conv2D)             (None, 5, 5, 192)    393216      ['average_pooling2d_8[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_85 (BatchN  (None, 5, 5, 320)   960         ['conv2d_89[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_87 (Activation)     (None, 5, 5, 384)    0           ['batch_normalization_87[0][0]'] \n",
      "                                                                                                  \n",
      " activation_88 (Activation)     (None, 5, 5, 384)    0           ['batch_normalization_88[0][0]'] \n",
      "                                                                                                  \n",
      " activation_91 (Activation)     (None, 5, 5, 384)    0           ['batch_normalization_91[0][0]'] \n",
      "                                                                                                  \n",
      " activation_92 (Activation)     (None, 5, 5, 384)    0           ['batch_normalization_92[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_93 (BatchN  (None, 5, 5, 192)   576         ['conv2d_97[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_85 (Activation)     (None, 5, 5, 320)    0           ['batch_normalization_85[0][0]'] \n",
      "                                                                                                  \n",
      " mixed9_1 (Concatenate)         (None, 5, 5, 768)    0           ['activation_87[0][0]',          \n",
      "                                                                  'activation_88[0][0]']          \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 5, 5, 768)    0           ['activation_91[0][0]',          \n",
      "                                                                  'activation_92[0][0]']          \n",
      "                                                                                                  \n",
      " activation_93 (Activation)     (None, 5, 5, 192)    0           ['batch_normalization_93[0][0]'] \n",
      "                                                                                                  \n",
      " mixed10 (Concatenate)          (None, 5, 5, 2048)   0           ['activation_85[0][0]',          \n",
      "                                                                  'mixed9_1[0][0]',               \n",
      "                                                                  'concatenate_1[0][0]',          \n",
      "                                                                  'activation_93[0][0]']          \n",
      "                                                                                                  \n",
      " flatten_1 (Flatten)            (None, 51200)        0           ['mixed10[0][0]']                \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 51200)        0           ['flatten_1[0][0]']              \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 1024)         52429824    ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 1024)         0           ['dense_2[0][0]']                \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 1)            1025        ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 74,233,633\n",
      "Trainable params: 52,430,849\n",
      "Non-trainable params: 21,802,784\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2 = create_model_transfer()\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "13/13 [==============================] - 13s 524ms/step - loss: 30.2784 - accuracy: 0.5200 - val_loss: 4.0569 - val_accuracy: 0.6923\n",
      "Epoch 2/200\n",
      "13/13 [==============================] - 3s 204ms/step - loss: 6.7724 - accuracy: 0.7200 - val_loss: 4.3544 - val_accuracy: 0.6731\n",
      "Epoch 3/200\n",
      "13/13 [==============================] - 3s 220ms/step - loss: 4.1011 - accuracy: 0.8200 - val_loss: 3.5404 - val_accuracy: 0.7692\n",
      "Epoch 4/200\n",
      "13/13 [==============================] - 3s 205ms/step - loss: 2.7891 - accuracy: 0.8300 - val_loss: 3.4966 - val_accuracy: 0.7115\n",
      "Epoch 5/200\n",
      "13/13 [==============================] - 3s 205ms/step - loss: 3.2452 - accuracy: 0.7750 - val_loss: 4.8770 - val_accuracy: 0.6731\n",
      "Epoch 6/200\n",
      "13/13 [==============================] - 3s 200ms/step - loss: 2.0487 - accuracy: 0.7650 - val_loss: 1.3354 - val_accuracy: 0.7885\n",
      "Epoch 7/200\n",
      "13/13 [==============================] - 3s 217ms/step - loss: 1.9669 - accuracy: 0.7700 - val_loss: 2.1021 - val_accuracy: 0.8269\n",
      "Epoch 8/200\n",
      "13/13 [==============================] - 3s 195ms/step - loss: 1.7119 - accuracy: 0.8500 - val_loss: 1.7526 - val_accuracy: 0.8077\n",
      "Epoch 9/200\n",
      "13/13 [==============================] - 3s 194ms/step - loss: 1.4340 - accuracy: 0.8300 - val_loss: 1.4949 - val_accuracy: 0.7692\n",
      "Epoch 10/200\n",
      "13/13 [==============================] - 3s 195ms/step - loss: 1.1133 - accuracy: 0.8500 - val_loss: 1.5299 - val_accuracy: 0.7885\n",
      "Epoch 11/200\n",
      "13/13 [==============================] - 3s 198ms/step - loss: 1.2552 - accuracy: 0.8200 - val_loss: 1.9862 - val_accuracy: 0.7500\n",
      "Epoch 12/200\n",
      "13/13 [==============================] - 3s 212ms/step - loss: 0.8717 - accuracy: 0.8400 - val_loss: 0.9721 - val_accuracy: 0.7885\n",
      "Epoch 13/200\n",
      "13/13 [==============================] - 3s 206ms/step - loss: 0.6004 - accuracy: 0.8900 - val_loss: 0.6080 - val_accuracy: 0.7692\n",
      "Epoch 14/200\n",
      "13/13 [==============================] - 3s 211ms/step - loss: 0.4522 - accuracy: 0.8650 - val_loss: 0.7315 - val_accuracy: 0.7115\n",
      "Epoch 15/200\n",
      "13/13 [==============================] - 3s 212ms/step - loss: 0.4361 - accuracy: 0.8900 - val_loss: 0.7115 - val_accuracy: 0.7115\n",
      "Epoch 16/200\n",
      "13/13 [==============================] - 3s 209ms/step - loss: 0.3025 - accuracy: 0.8950 - val_loss: 0.8142 - val_accuracy: 0.7692\n",
      "Epoch 17/200\n",
      "13/13 [==============================] - 3s 209ms/step - loss: 0.4729 - accuracy: 0.8700 - val_loss: 0.6398 - val_accuracy: 0.8077\n",
      "Epoch 18/200\n",
      "13/13 [==============================] - 3s 229ms/step - loss: 0.4991 - accuracy: 0.8300 - val_loss: 0.6987 - val_accuracy: 0.6346\n",
      "Epoch 19/200\n",
      "13/13 [==============================] - 3s 201ms/step - loss: 0.2932 - accuracy: 0.8750 - val_loss: 0.5297 - val_accuracy: 0.7692\n",
      "Epoch 20/200\n",
      "13/13 [==============================] - 3s 207ms/step - loss: 0.2884 - accuracy: 0.8900 - val_loss: 0.4602 - val_accuracy: 0.8077\n",
      "Epoch 21/200\n",
      "13/13 [==============================] - 3s 196ms/step - loss: 0.2474 - accuracy: 0.9000 - val_loss: 0.5540 - val_accuracy: 0.8077\n",
      "Epoch 22/200\n",
      "13/13 [==============================] - 3s 217ms/step - loss: 0.3085 - accuracy: 0.8750 - val_loss: 0.4650 - val_accuracy: 0.8077\n",
      "Epoch 23/200\n",
      "13/13 [==============================] - 3s 213ms/step - loss: 0.2992 - accuracy: 0.9050 - val_loss: 0.4695 - val_accuracy: 0.7885\n",
      "Epoch 24/200\n",
      "13/13 [==============================] - 3s 224ms/step - loss: 0.2302 - accuracy: 0.9200 - val_loss: 0.6068 - val_accuracy: 0.6346\n",
      "Epoch 25/200\n",
      "13/13 [==============================] - 3s 206ms/step - loss: 0.2274 - accuracy: 0.9100 - val_loss: 0.5259 - val_accuracy: 0.8077\n",
      "Epoch 26/200\n",
      "13/13 [==============================] - 3s 206ms/step - loss: 0.2313 - accuracy: 0.9300 - val_loss: 0.4971 - val_accuracy: 0.7308\n",
      "Epoch 27/200\n",
      "13/13 [==============================] - 3s 201ms/step - loss: 0.1983 - accuracy: 0.9100 - val_loss: 0.5148 - val_accuracy: 0.7115\n",
      "Epoch 28/200\n",
      "13/13 [==============================] - 3s 236ms/step - loss: 0.3099 - accuracy: 0.8600 - val_loss: 0.6636 - val_accuracy: 0.7308\n",
      "Epoch 29/200\n",
      "13/13 [==============================] - 3s 193ms/step - loss: 0.2240 - accuracy: 0.9150 - val_loss: 0.5112 - val_accuracy: 0.7115\n",
      "Epoch 30/200\n",
      "13/13 [==============================] - 2s 175ms/step - loss: 0.2293 - accuracy: 0.9000 - val_loss: 0.5897 - val_accuracy: 0.7500\n",
      "Epoch 31/200\n",
      "13/13 [==============================] - 2s 182ms/step - loss: 0.1848 - accuracy: 0.9050 - val_loss: 0.5412 - val_accuracy: 0.7500\n",
      "Epoch 32/200\n",
      "13/13 [==============================] - 2s 185ms/step - loss: 0.2306 - accuracy: 0.9050 - val_loss: 0.5191 - val_accuracy: 0.7115\n",
      "Epoch 33/200\n",
      "13/13 [==============================] - 2s 179ms/step - loss: 0.2323 - accuracy: 0.9200 - val_loss: 0.6331 - val_accuracy: 0.8077\n",
      "Epoch 34/200\n",
      "13/13 [==============================] - 2s 173ms/step - loss: 0.1743 - accuracy: 0.9200 - val_loss: 0.5711 - val_accuracy: 0.7500\n",
      "Epoch 35/200\n",
      "13/13 [==============================] - 2s 165ms/step - loss: 0.1990 - accuracy: 0.9200 - val_loss: 0.6212 - val_accuracy: 0.7885\n",
      "Epoch 36/200\n",
      "13/13 [==============================] - 2s 175ms/step - loss: 0.2581 - accuracy: 0.8950 - val_loss: 0.6472 - val_accuracy: 0.7500\n",
      "Epoch 37/200\n",
      "13/13 [==============================] - 2s 174ms/step - loss: 0.2407 - accuracy: 0.9150 - val_loss: 0.6353 - val_accuracy: 0.7692\n",
      "Epoch 38/200\n",
      "13/13 [==============================] - 2s 175ms/step - loss: 0.2236 - accuracy: 0.9000 - val_loss: 0.5763 - val_accuracy: 0.7692\n",
      "Epoch 39/200\n",
      "13/13 [==============================] - 2s 166ms/step - loss: 0.1971 - accuracy: 0.9200 - val_loss: 0.5994 - val_accuracy: 0.6346\n",
      "Epoch 40/200\n",
      "13/13 [==============================] - 2s 166ms/step - loss: 0.2104 - accuracy: 0.9250 - val_loss: 0.9790 - val_accuracy: 0.7500\n",
      "Epoch 41/200\n",
      "13/13 [==============================] - 2s 164ms/step - loss: 0.3505 - accuracy: 0.8600 - val_loss: 0.7523 - val_accuracy: 0.6731\n",
      "Epoch 42/200\n",
      "13/13 [==============================] - 2s 164ms/step - loss: 0.4086 - accuracy: 0.8400 - val_loss: 0.6224 - val_accuracy: 0.7885\n",
      "Epoch 43/200\n",
      "13/13 [==============================] - 2s 164ms/step - loss: 0.2949 - accuracy: 0.8750 - val_loss: 0.6206 - val_accuracy: 0.7885\n",
      "Epoch 44/200\n",
      "13/13 [==============================] - 2s 185ms/step - loss: 0.1922 - accuracy: 0.9200 - val_loss: 0.6197 - val_accuracy: 0.7500\n",
      "Epoch 45/200\n",
      "13/13 [==============================] - 3s 188ms/step - loss: 0.2248 - accuracy: 0.8950 - val_loss: 0.6780 - val_accuracy: 0.7500\n",
      "Epoch 46/200\n",
      "13/13 [==============================] - 2s 170ms/step - loss: 0.1561 - accuracy: 0.9250 - val_loss: 0.7182 - val_accuracy: 0.7115\n",
      "Epoch 47/200\n",
      "13/13 [==============================] - 2s 170ms/step - loss: 0.1480 - accuracy: 0.9350 - val_loss: 0.7094 - val_accuracy: 0.7500\n",
      "Epoch 48/200\n",
      "13/13 [==============================] - 2s 176ms/step - loss: 0.2136 - accuracy: 0.9100 - val_loss: 0.6404 - val_accuracy: 0.7308\n",
      "Epoch 49/200\n",
      "13/13 [==============================] - 2s 164ms/step - loss: 0.2542 - accuracy: 0.9100 - val_loss: 0.5995 - val_accuracy: 0.7308\n",
      "Epoch 50/200\n",
      "13/13 [==============================] - 2s 174ms/step - loss: 0.2293 - accuracy: 0.9000 - val_loss: 0.5835 - val_accuracy: 0.7692\n",
      "Epoch 51/200\n",
      "13/13 [==============================] - 3s 201ms/step - loss: 0.2168 - accuracy: 0.9250 - val_loss: 0.6451 - val_accuracy: 0.7500\n",
      "Epoch 52/200\n",
      "13/13 [==============================] - 3s 195ms/step - loss: 0.1846 - accuracy: 0.9300 - val_loss: 0.5887 - val_accuracy: 0.7308\n",
      "Epoch 53/200\n",
      "13/13 [==============================] - 3s 194ms/step - loss: 0.1607 - accuracy: 0.9350 - val_loss: 0.6591 - val_accuracy: 0.6731\n",
      "Epoch 54/200\n",
      "13/13 [==============================] - 3s 189ms/step - loss: 0.1374 - accuracy: 0.9500 - val_loss: 0.6774 - val_accuracy: 0.7500\n",
      "Epoch 55/200\n",
      "13/13 [==============================] - 3s 194ms/step - loss: 0.2139 - accuracy: 0.9100 - val_loss: 0.7147 - val_accuracy: 0.7692\n",
      "Epoch 56/200\n",
      "13/13 [==============================] - 3s 196ms/step - loss: 0.1344 - accuracy: 0.9400 - val_loss: 0.7816 - val_accuracy: 0.7692\n",
      "Epoch 57/200\n",
      "13/13 [==============================] - 3s 193ms/step - loss: 0.1117 - accuracy: 0.9600 - val_loss: 0.6829 - val_accuracy: 0.7692\n",
      "Epoch 58/200\n",
      "13/13 [==============================] - 2s 186ms/step - loss: 0.1691 - accuracy: 0.9300 - val_loss: 0.6546 - val_accuracy: 0.7500\n",
      "Epoch 59/200\n",
      "13/13 [==============================] - 3s 191ms/step - loss: 0.1532 - accuracy: 0.9350 - val_loss: 0.8153 - val_accuracy: 0.7308\n",
      "Epoch 60/200\n",
      "13/13 [==============================] - 3s 191ms/step - loss: 0.0992 - accuracy: 0.9550 - val_loss: 0.8178 - val_accuracy: 0.7308\n",
      "Epoch 61/200\n",
      "13/13 [==============================] - 3s 191ms/step - loss: 0.1553 - accuracy: 0.9250 - val_loss: 0.9017 - val_accuracy: 0.7308\n",
      "Epoch 62/200\n",
      "13/13 [==============================] - 3s 190ms/step - loss: 0.2106 - accuracy: 0.9100 - val_loss: 0.8675 - val_accuracy: 0.7115\n",
      "Epoch 63/200\n",
      "13/13 [==============================] - 3s 188ms/step - loss: 0.1726 - accuracy: 0.9200 - val_loss: 0.7654 - val_accuracy: 0.7115\n",
      "Epoch 64/200\n",
      "13/13 [==============================] - 3s 191ms/step - loss: 0.1586 - accuracy: 0.9450 - val_loss: 1.0479 - val_accuracy: 0.7308\n",
      "Epoch 65/200\n",
      "13/13 [==============================] - 3s 188ms/step - loss: 0.3197 - accuracy: 0.8900 - val_loss: 0.7053 - val_accuracy: 0.7692\n",
      "Epoch 66/200\n",
      "13/13 [==============================] - 2s 185ms/step - loss: 0.2225 - accuracy: 0.8950 - val_loss: 0.6855 - val_accuracy: 0.7500\n",
      "Epoch 67/200\n",
      "13/13 [==============================] - 2s 184ms/step - loss: 0.2348 - accuracy: 0.9000 - val_loss: 0.6307 - val_accuracy: 0.7885\n",
      "Epoch 68/200\n",
      "13/13 [==============================] - 3s 187ms/step - loss: 0.1461 - accuracy: 0.9600 - val_loss: 0.6293 - val_accuracy: 0.7308\n",
      "Epoch 69/200\n",
      "13/13 [==============================] - 2s 186ms/step - loss: 0.1250 - accuracy: 0.9650 - val_loss: 0.6866 - val_accuracy: 0.7115\n",
      "Epoch 70/200\n",
      "13/13 [==============================] - 3s 187ms/step - loss: 0.1674 - accuracy: 0.9450 - val_loss: 0.6363 - val_accuracy: 0.7885\n",
      "Epoch 71/200\n",
      "13/13 [==============================] - 3s 191ms/step - loss: 0.1125 - accuracy: 0.9450 - val_loss: 0.6510 - val_accuracy: 0.7885\n",
      "Epoch 72/200\n",
      "13/13 [==============================] - 2s 186ms/step - loss: 0.1960 - accuracy: 0.9150 - val_loss: 0.6338 - val_accuracy: 0.8077\n",
      "Epoch 73/200\n",
      "13/13 [==============================] - 3s 188ms/step - loss: 0.1792 - accuracy: 0.9300 - val_loss: 0.6079 - val_accuracy: 0.7692\n",
      "Epoch 74/200\n",
      "13/13 [==============================] - 2s 184ms/step - loss: 0.3479 - accuracy: 0.8350 - val_loss: 0.8551 - val_accuracy: 0.7500\n",
      "Epoch 75/200\n",
      "13/13 [==============================] - 3s 200ms/step - loss: 0.1527 - accuracy: 0.9500 - val_loss: 0.6670 - val_accuracy: 0.7500\n",
      "Epoch 76/200\n",
      "13/13 [==============================] - 3s 192ms/step - loss: 0.1862 - accuracy: 0.9350 - val_loss: 0.7458 - val_accuracy: 0.7885\n",
      "Epoch 77/200\n",
      "13/13 [==============================] - 3s 189ms/step - loss: 0.1213 - accuracy: 0.9500 - val_loss: 0.5467 - val_accuracy: 0.8269\n",
      "Epoch 78/200\n",
      "13/13 [==============================] - 3s 192ms/step - loss: 0.0921 - accuracy: 0.9650 - val_loss: 0.5077 - val_accuracy: 0.7885\n",
      "Epoch 79/200\n",
      "13/13 [==============================] - 2s 186ms/step - loss: 0.1219 - accuracy: 0.9500 - val_loss: 0.6137 - val_accuracy: 0.8269\n",
      "Epoch 80/200\n",
      "13/13 [==============================] - 3s 192ms/step - loss: 0.1381 - accuracy: 0.9650 - val_loss: 0.6377 - val_accuracy: 0.8269\n",
      "Epoch 81/200\n",
      "13/13 [==============================] - 3s 189ms/step - loss: 0.1612 - accuracy: 0.9400 - val_loss: 0.5899 - val_accuracy: 0.8077\n",
      "Epoch 82/200\n",
      "13/13 [==============================] - 3s 190ms/step - loss: 0.2088 - accuracy: 0.9300 - val_loss: 0.6261 - val_accuracy: 0.8269\n",
      "Epoch 83/200\n",
      "13/13 [==============================] - 3s 192ms/step - loss: 0.2295 - accuracy: 0.9300 - val_loss: 0.6209 - val_accuracy: 0.7692\n",
      "Epoch 84/200\n",
      "13/13 [==============================] - 3s 188ms/step - loss: 0.0813 - accuracy: 0.9750 - val_loss: 0.6936 - val_accuracy: 0.8077\n",
      "Epoch 85/200\n",
      "13/13 [==============================] - 3s 193ms/step - loss: 0.0714 - accuracy: 0.9850 - val_loss: 0.5672 - val_accuracy: 0.7885\n",
      "Epoch 86/200\n",
      "13/13 [==============================] - 2s 185ms/step - loss: 0.0666 - accuracy: 0.9750 - val_loss: 0.7435 - val_accuracy: 0.8077\n",
      "Epoch 87/200\n",
      "13/13 [==============================] - 3s 188ms/step - loss: 0.1946 - accuracy: 0.9450 - val_loss: 0.6379 - val_accuracy: 0.8269\n",
      "Epoch 88/200\n",
      "13/13 [==============================] - 2s 186ms/step - loss: 0.1146 - accuracy: 0.9550 - val_loss: 0.6537 - val_accuracy: 0.8269\n",
      "Epoch 89/200\n",
      "13/13 [==============================] - 3s 190ms/step - loss: 0.0836 - accuracy: 0.9550 - val_loss: 0.6291 - val_accuracy: 0.8269\n",
      "Epoch 90/200\n",
      "13/13 [==============================] - 3s 192ms/step - loss: 0.1276 - accuracy: 0.9650 - val_loss: 0.6980 - val_accuracy: 0.7692\n",
      "Epoch 91/200\n",
      "13/13 [==============================] - 3s 191ms/step - loss: 0.1227 - accuracy: 0.9500 - val_loss: 0.7183 - val_accuracy: 0.8077\n",
      "Epoch 92/200\n",
      "13/13 [==============================] - 3s 190ms/step - loss: 0.0841 - accuracy: 0.9700 - val_loss: 0.6336 - val_accuracy: 0.8077\n",
      "Epoch 93/200\n",
      "13/13 [==============================] - 3s 190ms/step - loss: 0.1054 - accuracy: 0.9600 - val_loss: 0.6793 - val_accuracy: 0.8269\n",
      "Epoch 94/200\n",
      "13/13 [==============================] - 3s 193ms/step - loss: 0.1322 - accuracy: 0.9500 - val_loss: 0.9125 - val_accuracy: 0.7115\n",
      "Epoch 95/200\n",
      "13/13 [==============================] - 3s 193ms/step - loss: 0.3760 - accuracy: 0.8700 - val_loss: 0.7934 - val_accuracy: 0.7692\n",
      "Epoch 96/200\n",
      "13/13 [==============================] - 3s 187ms/step - loss: 0.2752 - accuracy: 0.9100 - val_loss: 0.7477 - val_accuracy: 0.8077\n",
      "Epoch 97/200\n",
      "13/13 [==============================] - 3s 192ms/step - loss: 0.0864 - accuracy: 0.9650 - val_loss: 0.7433 - val_accuracy: 0.7692\n",
      "Epoch 98/200\n",
      "13/13 [==============================] - 3s 190ms/step - loss: 0.1961 - accuracy: 0.9350 - val_loss: 0.8089 - val_accuracy: 0.7692\n",
      "Epoch 99/200\n",
      "13/13 [==============================] - 3s 190ms/step - loss: 0.1731 - accuracy: 0.9350 - val_loss: 0.6619 - val_accuracy: 0.7885\n",
      "Epoch 100/200\n",
      "13/13 [==============================] - 3s 189ms/step - loss: 0.1150 - accuracy: 0.9650 - val_loss: 0.5653 - val_accuracy: 0.7885\n",
      "Epoch 101/200\n",
      "13/13 [==============================] - 3s 189ms/step - loss: 0.1637 - accuracy: 0.9200 - val_loss: 0.6896 - val_accuracy: 0.7308\n",
      "Epoch 102/200\n",
      "13/13 [==============================] - 3s 190ms/step - loss: 0.1322 - accuracy: 0.9550 - val_loss: 0.6995 - val_accuracy: 0.8077\n",
      "Epoch 103/200\n",
      "13/13 [==============================] - 3s 189ms/step - loss: 0.0699 - accuracy: 0.9800 - val_loss: 0.6629 - val_accuracy: 0.8462\n",
      "Epoch 104/200\n",
      "13/13 [==============================] - 3s 190ms/step - loss: 0.0892 - accuracy: 0.9700 - val_loss: 0.6374 - val_accuracy: 0.8269\n",
      "Epoch 105/200\n",
      "13/13 [==============================] - 3s 197ms/step - loss: 0.0504 - accuracy: 0.9750 - val_loss: 0.5692 - val_accuracy: 0.8077\n",
      "Epoch 106/200\n",
      "13/13 [==============================] - 3s 191ms/step - loss: 0.1643 - accuracy: 0.9600 - val_loss: 0.6596 - val_accuracy: 0.8077\n",
      "Epoch 107/200\n",
      "13/13 [==============================] - 3s 193ms/step - loss: 0.1188 - accuracy: 0.9500 - val_loss: 0.6500 - val_accuracy: 0.8269\n",
      "Epoch 108/200\n",
      "13/13 [==============================] - 3s 189ms/step - loss: 0.0671 - accuracy: 0.9750 - val_loss: 0.7050 - val_accuracy: 0.8077\n",
      "Epoch 109/200\n",
      "13/13 [==============================] - 3s 193ms/step - loss: 0.0978 - accuracy: 0.9750 - val_loss: 0.6443 - val_accuracy: 0.7885\n",
      "Epoch 110/200\n",
      "13/13 [==============================] - 3s 187ms/step - loss: 0.1283 - accuracy: 0.9500 - val_loss: 0.7486 - val_accuracy: 0.7885\n",
      "Epoch 111/200\n",
      "13/13 [==============================] - 3s 203ms/step - loss: 0.0269 - accuracy: 0.9950 - val_loss: 0.6116 - val_accuracy: 0.8077\n",
      "Epoch 112/200\n",
      "13/13 [==============================] - 3s 188ms/step - loss: 0.0748 - accuracy: 0.9750 - val_loss: 0.7619 - val_accuracy: 0.7885\n",
      "Epoch 113/200\n",
      "13/13 [==============================] - 3s 191ms/step - loss: 0.0939 - accuracy: 0.9600 - val_loss: 0.9521 - val_accuracy: 0.8077\n",
      "Epoch 114/200\n",
      "13/13 [==============================] - 3s 190ms/step - loss: 0.0953 - accuracy: 0.9700 - val_loss: 0.6629 - val_accuracy: 0.8077\n",
      "Epoch 115/200\n",
      "13/13 [==============================] - 3s 187ms/step - loss: 0.1968 - accuracy: 0.9250 - val_loss: 0.7120 - val_accuracy: 0.8269\n",
      "Epoch 116/200\n",
      "13/13 [==============================] - 3s 190ms/step - loss: 0.1136 - accuracy: 0.9600 - val_loss: 0.6747 - val_accuracy: 0.7692\n",
      "Epoch 117/200\n",
      "13/13 [==============================] - 3s 190ms/step - loss: 0.1484 - accuracy: 0.9400 - val_loss: 0.6377 - val_accuracy: 0.7308\n",
      "Epoch 118/200\n",
      "13/13 [==============================] - 3s 192ms/step - loss: 0.0814 - accuracy: 0.9800 - val_loss: 0.7019 - val_accuracy: 0.8077\n",
      "Epoch 119/200\n",
      "13/13 [==============================] - 3s 194ms/step - loss: 0.0719 - accuracy: 0.9800 - val_loss: 0.6221 - val_accuracy: 0.8077\n",
      "Epoch 120/200\n",
      "13/13 [==============================] - 3s 193ms/step - loss: 0.1130 - accuracy: 0.9550 - val_loss: 0.9178 - val_accuracy: 0.7692\n",
      "Epoch 121/200\n",
      "13/13 [==============================] - 3s 190ms/step - loss: 0.1597 - accuracy: 0.9400 - val_loss: 0.8267 - val_accuracy: 0.7692\n",
      "Epoch 122/200\n",
      "13/13 [==============================] - 3s 190ms/step - loss: 0.1828 - accuracy: 0.9450 - val_loss: 0.7653 - val_accuracy: 0.7308\n",
      "Epoch 123/200\n",
      "13/13 [==============================] - 3s 193ms/step - loss: 0.0897 - accuracy: 0.9650 - val_loss: 0.7592 - val_accuracy: 0.7692\n",
      "Epoch 124/200\n",
      "13/13 [==============================] - 3s 191ms/step - loss: 0.0557 - accuracy: 0.9850 - val_loss: 0.6559 - val_accuracy: 0.7885\n",
      "Epoch 125/200\n",
      "13/13 [==============================] - 3s 190ms/step - loss: 0.1266 - accuracy: 0.9450 - val_loss: 0.6499 - val_accuracy: 0.8077\n",
      "Epoch 126/200\n",
      "13/13 [==============================] - 3s 195ms/step - loss: 0.1143 - accuracy: 0.9600 - val_loss: 0.8068 - val_accuracy: 0.7308\n",
      "Epoch 127/200\n",
      "13/13 [==============================] - 3s 191ms/step - loss: 0.1045 - accuracy: 0.9700 - val_loss: 0.6055 - val_accuracy: 0.8077\n",
      "Epoch 128/200\n",
      "13/13 [==============================] - 3s 189ms/step - loss: 0.1107 - accuracy: 0.9600 - val_loss: 0.6657 - val_accuracy: 0.7885\n",
      "Epoch 129/200\n",
      "13/13 [==============================] - 3s 194ms/step - loss: 0.1126 - accuracy: 0.9500 - val_loss: 0.6711 - val_accuracy: 0.7692\n",
      "Epoch 130/200\n",
      "13/13 [==============================] - 3s 189ms/step - loss: 0.1066 - accuracy: 0.9600 - val_loss: 0.8472 - val_accuracy: 0.7885\n",
      "Epoch 131/200\n",
      "13/13 [==============================] - 3s 192ms/step - loss: 0.0966 - accuracy: 0.9600 - val_loss: 0.9206 - val_accuracy: 0.7115\n",
      "Epoch 132/200\n",
      "13/13 [==============================] - 3s 188ms/step - loss: 0.1321 - accuracy: 0.9600 - val_loss: 0.9391 - val_accuracy: 0.7692\n",
      "Epoch 133/200\n",
      "13/13 [==============================] - 2s 182ms/step - loss: 0.1125 - accuracy: 0.9400 - val_loss: 0.7301 - val_accuracy: 0.7500\n",
      "Epoch 134/200\n",
      "13/13 [==============================] - 3s 192ms/step - loss: 0.1222 - accuracy: 0.9500 - val_loss: 0.6197 - val_accuracy: 0.7885\n",
      "Epoch 135/200\n",
      "13/13 [==============================] - 3s 189ms/step - loss: 0.1118 - accuracy: 0.9700 - val_loss: 0.7047 - val_accuracy: 0.8077\n",
      "Epoch 136/200\n",
      "13/13 [==============================] - 3s 191ms/step - loss: 0.0925 - accuracy: 0.9750 - val_loss: 0.6625 - val_accuracy: 0.8077\n",
      "Epoch 137/200\n",
      "13/13 [==============================] - 2s 187ms/step - loss: 0.0444 - accuracy: 0.9900 - val_loss: 0.6933 - val_accuracy: 0.8654\n",
      "Epoch 138/200\n",
      "13/13 [==============================] - 3s 191ms/step - loss: 0.1028 - accuracy: 0.9550 - val_loss: 0.7358 - val_accuracy: 0.8462\n",
      "Epoch 139/200\n",
      "13/13 [==============================] - 3s 191ms/step - loss: 0.0940 - accuracy: 0.9600 - val_loss: 0.7541 - val_accuracy: 0.7692\n",
      "Epoch 140/200\n",
      "13/13 [==============================] - 3s 192ms/step - loss: 0.1519 - accuracy: 0.9350 - val_loss: 0.6676 - val_accuracy: 0.8269\n",
      "Epoch 141/200\n",
      "13/13 [==============================] - 3s 192ms/step - loss: 0.0968 - accuracy: 0.9750 - val_loss: 0.6975 - val_accuracy: 0.8077\n",
      "Epoch 142/200\n",
      "13/13 [==============================] - 3s 199ms/step - loss: 0.0899 - accuracy: 0.9750 - val_loss: 0.5315 - val_accuracy: 0.8269\n",
      "Epoch 143/200\n",
      "13/13 [==============================] - 3s 191ms/step - loss: 0.0826 - accuracy: 0.9700 - val_loss: 0.5863 - val_accuracy: 0.8269\n",
      "Epoch 144/200\n",
      "13/13 [==============================] - 3s 194ms/step - loss: 0.0334 - accuracy: 0.9900 - val_loss: 0.6831 - val_accuracy: 0.8077\n",
      "Epoch 145/200\n",
      "13/13 [==============================] - 3s 189ms/step - loss: 0.0477 - accuracy: 0.9800 - val_loss: 0.7298 - val_accuracy: 0.7885\n",
      "Epoch 146/200\n",
      "13/13 [==============================] - 3s 191ms/step - loss: 0.0973 - accuracy: 0.9700 - val_loss: 0.6735 - val_accuracy: 0.8077\n",
      "Epoch 147/200\n",
      "13/13 [==============================] - 3s 191ms/step - loss: 0.0909 - accuracy: 0.9550 - val_loss: 0.7756 - val_accuracy: 0.8269\n",
      "Epoch 148/200\n",
      "13/13 [==============================] - 3s 191ms/step - loss: 0.0742 - accuracy: 0.9650 - val_loss: 0.5651 - val_accuracy: 0.8269\n",
      "Epoch 149/200\n",
      "13/13 [==============================] - 3s 192ms/step - loss: 0.0753 - accuracy: 0.9700 - val_loss: 0.8802 - val_accuracy: 0.8269\n",
      "Epoch 150/200\n",
      "13/13 [==============================] - 3s 188ms/step - loss: 0.0900 - accuracy: 0.9600 - val_loss: 0.6228 - val_accuracy: 0.8077\n",
      "Epoch 151/200\n",
      "13/13 [==============================] - 3s 190ms/step - loss: 0.1282 - accuracy: 0.9500 - val_loss: 0.5828 - val_accuracy: 0.7885\n",
      "Epoch 152/200\n",
      "13/13 [==============================] - 3s 194ms/step - loss: 0.1283 - accuracy: 0.9450 - val_loss: 0.6532 - val_accuracy: 0.7885\n",
      "Epoch 153/200\n",
      "13/13 [==============================] - 3s 193ms/step - loss: 0.1046 - accuracy: 0.9600 - val_loss: 0.7360 - val_accuracy: 0.7885\n",
      "Epoch 154/200\n",
      "13/13 [==============================] - 3s 192ms/step - loss: 0.0741 - accuracy: 0.9800 - val_loss: 0.6412 - val_accuracy: 0.7885\n",
      "Epoch 155/200\n",
      "13/13 [==============================] - 3s 191ms/step - loss: 0.1433 - accuracy: 0.9550 - val_loss: 0.8979 - val_accuracy: 0.7885\n",
      "Epoch 156/200\n",
      "13/13 [==============================] - 3s 190ms/step - loss: 0.0845 - accuracy: 0.9700 - val_loss: 0.6152 - val_accuracy: 0.8462\n",
      "Epoch 157/200\n",
      "13/13 [==============================] - 3s 199ms/step - loss: 0.0713 - accuracy: 0.9700 - val_loss: 0.5284 - val_accuracy: 0.8654\n",
      "Epoch 158/200\n",
      "13/13 [==============================] - 3s 189ms/step - loss: 0.0577 - accuracy: 0.9800 - val_loss: 0.5466 - val_accuracy: 0.8462\n",
      "Epoch 159/200\n",
      "13/13 [==============================] - 2s 187ms/step - loss: 0.0446 - accuracy: 0.9750 - val_loss: 0.5395 - val_accuracy: 0.8462\n",
      "Epoch 160/200\n",
      "13/13 [==============================] - 3s 188ms/step - loss: 0.0569 - accuracy: 0.9900 - val_loss: 0.6327 - val_accuracy: 0.7885\n",
      "Epoch 161/200\n",
      "13/13 [==============================] - 3s 192ms/step - loss: 0.1095 - accuracy: 0.9600 - val_loss: 0.5989 - val_accuracy: 0.8077\n",
      "Epoch 162/200\n",
      "13/13 [==============================] - 3s 190ms/step - loss: 0.0757 - accuracy: 0.9750 - val_loss: 0.6338 - val_accuracy: 0.8462\n",
      "Epoch 163/200\n",
      "13/13 [==============================] - 3s 189ms/step - loss: 0.0803 - accuracy: 0.9800 - val_loss: 0.7641 - val_accuracy: 0.8269\n",
      "Epoch 164/200\n",
      "13/13 [==============================] - 3s 190ms/step - loss: 0.1287 - accuracy: 0.9550 - val_loss: 0.6777 - val_accuracy: 0.8269\n",
      "Epoch 165/200\n",
      "13/13 [==============================] - 3s 192ms/step - loss: 0.1616 - accuracy: 0.9500 - val_loss: 0.6893 - val_accuracy: 0.8077\n",
      "Epoch 166/200\n",
      "13/13 [==============================] - 3s 197ms/step - loss: 0.0743 - accuracy: 0.9700 - val_loss: 0.7495 - val_accuracy: 0.7692\n",
      "Epoch 167/200\n",
      "13/13 [==============================] - 3s 190ms/step - loss: 0.0758 - accuracy: 0.9800 - val_loss: 0.6766 - val_accuracy: 0.8269\n",
      "Epoch 168/200\n",
      "13/13 [==============================] - 3s 189ms/step - loss: 0.0573 - accuracy: 0.9900 - val_loss: 0.5887 - val_accuracy: 0.8269\n",
      "Epoch 169/200\n",
      "13/13 [==============================] - 3s 193ms/step - loss: 0.1076 - accuracy: 0.9550 - val_loss: 0.5638 - val_accuracy: 0.8462\n",
      "Epoch 170/200\n",
      "13/13 [==============================] - 3s 191ms/step - loss: 0.1034 - accuracy: 0.9450 - val_loss: 0.6818 - val_accuracy: 0.8269\n",
      "Epoch 171/200\n",
      "13/13 [==============================] - 3s 194ms/step - loss: 0.1118 - accuracy: 0.9600 - val_loss: 0.8027 - val_accuracy: 0.7115\n",
      "Epoch 172/200\n",
      "13/13 [==============================] - 3s 190ms/step - loss: 0.0799 - accuracy: 0.9700 - val_loss: 0.7613 - val_accuracy: 0.7308\n",
      "Epoch 173/200\n",
      "13/13 [==============================] - 3s 191ms/step - loss: 0.0976 - accuracy: 0.9450 - val_loss: 0.9144 - val_accuracy: 0.7308\n",
      "Epoch 174/200\n",
      "13/13 [==============================] - 3s 188ms/step - loss: 0.0658 - accuracy: 0.9750 - val_loss: 0.9742 - val_accuracy: 0.7692\n",
      "Epoch 175/200\n",
      "13/13 [==============================] - 3s 189ms/step - loss: 0.1823 - accuracy: 0.9450 - val_loss: 0.7960 - val_accuracy: 0.8462\n",
      "Epoch 176/200\n",
      "13/13 [==============================] - 3s 190ms/step - loss: 0.2034 - accuracy: 0.9300 - val_loss: 0.9277 - val_accuracy: 0.7115\n",
      "Epoch 177/200\n",
      "13/13 [==============================] - 3s 196ms/step - loss: 0.0769 - accuracy: 0.9750 - val_loss: 0.9363 - val_accuracy: 0.7885\n",
      "Epoch 178/200\n",
      "13/13 [==============================] - 3s 191ms/step - loss: 0.1332 - accuracy: 0.9450 - val_loss: 0.8745 - val_accuracy: 0.8077\n",
      "Epoch 179/200\n",
      "13/13 [==============================] - 3s 194ms/step - loss: 0.0847 - accuracy: 0.9750 - val_loss: 0.9409 - val_accuracy: 0.7308\n",
      "Epoch 180/200\n",
      "13/13 [==============================] - 3s 189ms/step - loss: 0.1139 - accuracy: 0.9500 - val_loss: 0.6045 - val_accuracy: 0.8077\n",
      "Epoch 181/200\n",
      "13/13 [==============================] - 3s 191ms/step - loss: 0.0835 - accuracy: 0.9700 - val_loss: 0.8306 - val_accuracy: 0.8077\n",
      "Epoch 182/200\n",
      "13/13 [==============================] - 3s 192ms/step - loss: 0.0985 - accuracy: 0.9650 - val_loss: 0.9784 - val_accuracy: 0.7308\n",
      "Epoch 183/200\n",
      "13/13 [==============================] - 3s 191ms/step - loss: 0.2096 - accuracy: 0.9000 - val_loss: 0.7419 - val_accuracy: 0.8462\n",
      "Epoch 184/200\n",
      "13/13 [==============================] - 3s 190ms/step - loss: 0.0635 - accuracy: 0.9800 - val_loss: 0.7516 - val_accuracy: 0.8269\n",
      "Epoch 185/200\n",
      "13/13 [==============================] - 3s 190ms/step - loss: 0.1736 - accuracy: 0.9500 - val_loss: 0.5543 - val_accuracy: 0.7500\n",
      "Epoch 186/200\n",
      "13/13 [==============================] - 3s 195ms/step - loss: 0.0619 - accuracy: 0.9800 - val_loss: 0.4751 - val_accuracy: 0.7885\n",
      "Epoch 187/200\n",
      "13/13 [==============================] - 3s 189ms/step - loss: 0.0991 - accuracy: 0.9800 - val_loss: 0.5023 - val_accuracy: 0.8654\n",
      "Epoch 188/200\n",
      "13/13 [==============================] - 3s 187ms/step - loss: 0.1020 - accuracy: 0.9600 - val_loss: 0.7373 - val_accuracy: 0.8462\n",
      "Epoch 189/200\n",
      "13/13 [==============================] - 3s 193ms/step - loss: 0.0673 - accuracy: 0.9650 - val_loss: 0.7090 - val_accuracy: 0.8462\n",
      "Epoch 190/200\n",
      "13/13 [==============================] - 3s 201ms/step - loss: 0.0504 - accuracy: 0.9800 - val_loss: 0.7722 - val_accuracy: 0.8077\n",
      "Epoch 191/200\n",
      "13/13 [==============================] - 3s 194ms/step - loss: 0.0810 - accuracy: 0.9850 - val_loss: 0.7636 - val_accuracy: 0.7885\n",
      "Epoch 192/200\n",
      "13/13 [==============================] - 3s 188ms/step - loss: 0.0722 - accuracy: 0.9700 - val_loss: 0.7283 - val_accuracy: 0.8269\n",
      "Epoch 193/200\n",
      "13/13 [==============================] - 3s 188ms/step - loss: 0.1180 - accuracy: 0.9700 - val_loss: 0.6459 - val_accuracy: 0.8462\n",
      "Epoch 194/200\n",
      "13/13 [==============================] - 3s 192ms/step - loss: 0.0490 - accuracy: 0.9850 - val_loss: 0.7272 - val_accuracy: 0.8269\n",
      "Epoch 195/200\n",
      "13/13 [==============================] - 2s 182ms/step - loss: 0.1139 - accuracy: 0.9750 - val_loss: 0.7001 - val_accuracy: 0.7500\n",
      "Epoch 196/200\n",
      "13/13 [==============================] - 2s 184ms/step - loss: 0.0571 - accuracy: 0.9700 - val_loss: 0.6006 - val_accuracy: 0.8462\n",
      "Epoch 197/200\n",
      "13/13 [==============================] - 2s 167ms/step - loss: 0.0424 - accuracy: 0.9850 - val_loss: 0.6393 - val_accuracy: 0.8077\n",
      "Epoch 198/200\n",
      "13/13 [==============================] - 2s 164ms/step - loss: 0.0648 - accuracy: 0.9850 - val_loss: 0.6571 - val_accuracy: 0.8462\n",
      "Epoch 199/200\n",
      "13/13 [==============================] - 2s 165ms/step - loss: 0.1010 - accuracy: 0.9550 - val_loss: 0.5981 - val_accuracy: 0.8462\n",
      "Epoch 200/200\n",
      "13/13 [==============================] - 2s 162ms/step - loss: 0.1301 - accuracy: 0.9500 - val_loss: 0.6874 - val_accuracy: 0.8269\n"
     ]
    }
   ],
   "source": [
    "history1 = model2.fit(\n",
    "    train_generator,\n",
    "    epochs=200,\n",
    "    validation_data=test_generator,\n",
    "    steps_per_epoch=len(train_generator)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'acc'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/media/DATA/projects/monkey pox project/notebooks/workbook2.ipynb Cell 13\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/media/DATA/projects/monkey%20pox%20project/notebooks/workbook2.ipynb#ch0000011?line=0'>1</a>\u001b[0m plot_history(history1)\n",
      "\u001b[1;32m/media/DATA/projects/monkey pox project/notebooks/workbook2.ipynb Cell 13\u001b[0m in \u001b[0;36mplot_history\u001b[0;34m(history)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/media/DATA/projects/monkey%20pox%20project/notebooks/workbook2.ipynb#ch0000011?line=2'>3</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mplot_history\u001b[39m(history):\n\u001b[0;32m----> <a href='vscode-notebook-cell:/media/DATA/projects/monkey%20pox%20project/notebooks/workbook2.ipynb#ch0000011?line=3'>4</a>\u001b[0m     acc \u001b[39m=\u001b[39m history\u001b[39m.\u001b[39;49mhistory[\u001b[39m\"\u001b[39;49m\u001b[39macc\u001b[39;49m\u001b[39m\"\u001b[39;49m]\n\u001b[1;32m      <a href='vscode-notebook-cell:/media/DATA/projects/monkey%20pox%20project/notebooks/workbook2.ipynb#ch0000011?line=4'>5</a>\u001b[0m     val_acc \u001b[39m=\u001b[39m history\u001b[39m.\u001b[39mhistory[\u001b[39m\"\u001b[39m\u001b[39mval_acc\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m      <a href='vscode-notebook-cell:/media/DATA/projects/monkey%20pox%20project/notebooks/workbook2.ipynb#ch0000011?line=5'>6</a>\u001b[0m     loss \u001b[39m=\u001b[39m history\u001b[39m.\u001b[39mhistory[\u001b[39m\"\u001b[39m\u001b[39mloss\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "\u001b[0;31mKeyError\u001b[0m: 'acc'"
     ]
    }
   ],
   "source": [
    "plot_history(history1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer learning with the fold1 directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir_1 = \"../datasets/archive/Fold1/Fold1/Fold1/\"\n",
    "train_dir_1 = os.path.join(base_dir_1, \"Train\")\n",
    "test_dir_1 = os.path.join(base_dir_1, \"Val\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_4 (InputLayer)           [(None, 224, 224, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d_282 (Conv2D)            (None, 111, 111, 32  864         ['input_4[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_282 (Batch  (None, 111, 111, 32  96         ['conv2d_282[0][0]']             \n",
      " Normalization)                 )                                                                 \n",
      "                                                                                                  \n",
      " activation_282 (Activation)    (None, 111, 111, 32  0           ['batch_normalization_282[0][0]']\n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_283 (Conv2D)            (None, 109, 109, 32  9216        ['activation_282[0][0]']         \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_283 (Batch  (None, 109, 109, 32  96         ['conv2d_283[0][0]']             \n",
      " Normalization)                 )                                                                 \n",
      "                                                                                                  \n",
      " activation_283 (Activation)    (None, 109, 109, 32  0           ['batch_normalization_283[0][0]']\n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_284 (Conv2D)            (None, 109, 109, 64  18432       ['activation_283[0][0]']         \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_284 (Batch  (None, 109, 109, 64  192        ['conv2d_284[0][0]']             \n",
      " Normalization)                 )                                                                 \n",
      "                                                                                                  \n",
      " activation_284 (Activation)    (None, 109, 109, 64  0           ['batch_normalization_284[0][0]']\n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d_12 (MaxPooling2D  (None, 54, 54, 64)  0           ['activation_284[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv2d_285 (Conv2D)            (None, 54, 54, 80)   5120        ['max_pooling2d_12[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_285 (Batch  (None, 54, 54, 80)  240         ['conv2d_285[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_285 (Activation)    (None, 54, 54, 80)   0           ['batch_normalization_285[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_286 (Conv2D)            (None, 52, 52, 192)  138240      ['activation_285[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_286 (Batch  (None, 52, 52, 192)  576        ['conv2d_286[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_286 (Activation)    (None, 52, 52, 192)  0           ['batch_normalization_286[0][0]']\n",
      "                                                                                                  \n",
      " max_pooling2d_13 (MaxPooling2D  (None, 25, 25, 192)  0          ['activation_286[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv2d_290 (Conv2D)            (None, 25, 25, 64)   12288       ['max_pooling2d_13[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_290 (Batch  (None, 25, 25, 64)  192         ['conv2d_290[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_290 (Activation)    (None, 25, 25, 64)   0           ['batch_normalization_290[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_288 (Conv2D)            (None, 25, 25, 48)   9216        ['max_pooling2d_13[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_291 (Conv2D)            (None, 25, 25, 96)   55296       ['activation_290[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_288 (Batch  (None, 25, 25, 48)  144         ['conv2d_288[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_291 (Batch  (None, 25, 25, 96)  288         ['conv2d_291[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_288 (Activation)    (None, 25, 25, 48)   0           ['batch_normalization_288[0][0]']\n",
      "                                                                                                  \n",
      " activation_291 (Activation)    (None, 25, 25, 96)   0           ['batch_normalization_291[0][0]']\n",
      "                                                                                                  \n",
      " average_pooling2d_27 (AverageP  (None, 25, 25, 192)  0          ['max_pooling2d_13[0][0]']       \n",
      " ooling2D)                                                                                        \n",
      "                                                                                                  \n",
      " conv2d_287 (Conv2D)            (None, 25, 25, 64)   12288       ['max_pooling2d_13[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_289 (Conv2D)            (None, 25, 25, 64)   76800       ['activation_288[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_292 (Conv2D)            (None, 25, 25, 96)   82944       ['activation_291[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_293 (Conv2D)            (None, 25, 25, 32)   6144        ['average_pooling2d_27[0][0]']   \n",
      "                                                                                                  \n",
      " batch_normalization_287 (Batch  (None, 25, 25, 64)  192         ['conv2d_287[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_289 (Batch  (None, 25, 25, 64)  192         ['conv2d_289[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_292 (Batch  (None, 25, 25, 96)  288         ['conv2d_292[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_293 (Batch  (None, 25, 25, 32)  96          ['conv2d_293[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_287 (Activation)    (None, 25, 25, 64)   0           ['batch_normalization_287[0][0]']\n",
      "                                                                                                  \n",
      " activation_289 (Activation)    (None, 25, 25, 64)   0           ['batch_normalization_289[0][0]']\n",
      "                                                                                                  \n",
      " activation_292 (Activation)    (None, 25, 25, 96)   0           ['batch_normalization_292[0][0]']\n",
      "                                                                                                  \n",
      " activation_293 (Activation)    (None, 25, 25, 32)   0           ['batch_normalization_293[0][0]']\n",
      "                                                                                                  \n",
      " mixed0 (Concatenate)           (None, 25, 25, 256)  0           ['activation_287[0][0]',         \n",
      "                                                                  'activation_289[0][0]',         \n",
      "                                                                  'activation_292[0][0]',         \n",
      "                                                                  'activation_293[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_297 (Conv2D)            (None, 25, 25, 64)   16384       ['mixed0[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_297 (Batch  (None, 25, 25, 64)  192         ['conv2d_297[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_297 (Activation)    (None, 25, 25, 64)   0           ['batch_normalization_297[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_295 (Conv2D)            (None, 25, 25, 48)   12288       ['mixed0[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_298 (Conv2D)            (None, 25, 25, 96)   55296       ['activation_297[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_295 (Batch  (None, 25, 25, 48)  144         ['conv2d_295[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_298 (Batch  (None, 25, 25, 96)  288         ['conv2d_298[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_295 (Activation)    (None, 25, 25, 48)   0           ['batch_normalization_295[0][0]']\n",
      "                                                                                                  \n",
      " activation_298 (Activation)    (None, 25, 25, 96)   0           ['batch_normalization_298[0][0]']\n",
      "                                                                                                  \n",
      " average_pooling2d_28 (AverageP  (None, 25, 25, 256)  0          ['mixed0[0][0]']                 \n",
      " ooling2D)                                                                                        \n",
      "                                                                                                  \n",
      " conv2d_294 (Conv2D)            (None, 25, 25, 64)   16384       ['mixed0[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_296 (Conv2D)            (None, 25, 25, 64)   76800       ['activation_295[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_299 (Conv2D)            (None, 25, 25, 96)   82944       ['activation_298[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_300 (Conv2D)            (None, 25, 25, 64)   16384       ['average_pooling2d_28[0][0]']   \n",
      "                                                                                                  \n",
      " batch_normalization_294 (Batch  (None, 25, 25, 64)  192         ['conv2d_294[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_296 (Batch  (None, 25, 25, 64)  192         ['conv2d_296[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_299 (Batch  (None, 25, 25, 96)  288         ['conv2d_299[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_300 (Batch  (None, 25, 25, 64)  192         ['conv2d_300[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_294 (Activation)    (None, 25, 25, 64)   0           ['batch_normalization_294[0][0]']\n",
      "                                                                                                  \n",
      " activation_296 (Activation)    (None, 25, 25, 64)   0           ['batch_normalization_296[0][0]']\n",
      "                                                                                                  \n",
      " activation_299 (Activation)    (None, 25, 25, 96)   0           ['batch_normalization_299[0][0]']\n",
      "                                                                                                  \n",
      " activation_300 (Activation)    (None, 25, 25, 64)   0           ['batch_normalization_300[0][0]']\n",
      "                                                                                                  \n",
      " mixed1 (Concatenate)           (None, 25, 25, 288)  0           ['activation_294[0][0]',         \n",
      "                                                                  'activation_296[0][0]',         \n",
      "                                                                  'activation_299[0][0]',         \n",
      "                                                                  'activation_300[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_304 (Conv2D)            (None, 25, 25, 64)   18432       ['mixed1[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_304 (Batch  (None, 25, 25, 64)  192         ['conv2d_304[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_304 (Activation)    (None, 25, 25, 64)   0           ['batch_normalization_304[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_302 (Conv2D)            (None, 25, 25, 48)   13824       ['mixed1[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_305 (Conv2D)            (None, 25, 25, 96)   55296       ['activation_304[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_302 (Batch  (None, 25, 25, 48)  144         ['conv2d_302[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_305 (Batch  (None, 25, 25, 96)  288         ['conv2d_305[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_302 (Activation)    (None, 25, 25, 48)   0           ['batch_normalization_302[0][0]']\n",
      "                                                                                                  \n",
      " activation_305 (Activation)    (None, 25, 25, 96)   0           ['batch_normalization_305[0][0]']\n",
      "                                                                                                  \n",
      " average_pooling2d_29 (AverageP  (None, 25, 25, 288)  0          ['mixed1[0][0]']                 \n",
      " ooling2D)                                                                                        \n",
      "                                                                                                  \n",
      " conv2d_301 (Conv2D)            (None, 25, 25, 64)   18432       ['mixed1[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_303 (Conv2D)            (None, 25, 25, 64)   76800       ['activation_302[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_306 (Conv2D)            (None, 25, 25, 96)   82944       ['activation_305[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_307 (Conv2D)            (None, 25, 25, 64)   18432       ['average_pooling2d_29[0][0]']   \n",
      "                                                                                                  \n",
      " batch_normalization_301 (Batch  (None, 25, 25, 64)  192         ['conv2d_301[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_303 (Batch  (None, 25, 25, 64)  192         ['conv2d_303[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_306 (Batch  (None, 25, 25, 96)  288         ['conv2d_306[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_307 (Batch  (None, 25, 25, 64)  192         ['conv2d_307[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_301 (Activation)    (None, 25, 25, 64)   0           ['batch_normalization_301[0][0]']\n",
      "                                                                                                  \n",
      " activation_303 (Activation)    (None, 25, 25, 64)   0           ['batch_normalization_303[0][0]']\n",
      "                                                                                                  \n",
      " activation_306 (Activation)    (None, 25, 25, 96)   0           ['batch_normalization_306[0][0]']\n",
      "                                                                                                  \n",
      " activation_307 (Activation)    (None, 25, 25, 64)   0           ['batch_normalization_307[0][0]']\n",
      "                                                                                                  \n",
      " mixed2 (Concatenate)           (None, 25, 25, 288)  0           ['activation_301[0][0]',         \n",
      "                                                                  'activation_303[0][0]',         \n",
      "                                                                  'activation_306[0][0]',         \n",
      "                                                                  'activation_307[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_309 (Conv2D)            (None, 25, 25, 64)   18432       ['mixed2[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_309 (Batch  (None, 25, 25, 64)  192         ['conv2d_309[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_309 (Activation)    (None, 25, 25, 64)   0           ['batch_normalization_309[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_310 (Conv2D)            (None, 25, 25, 96)   55296       ['activation_309[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_310 (Batch  (None, 25, 25, 96)  288         ['conv2d_310[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_310 (Activation)    (None, 25, 25, 96)   0           ['batch_normalization_310[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_308 (Conv2D)            (None, 12, 12, 384)  995328      ['mixed2[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_311 (Conv2D)            (None, 12, 12, 96)   82944       ['activation_310[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_308 (Batch  (None, 12, 12, 384)  1152       ['conv2d_308[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_311 (Batch  (None, 12, 12, 96)  288         ['conv2d_311[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_308 (Activation)    (None, 12, 12, 384)  0           ['batch_normalization_308[0][0]']\n",
      "                                                                                                  \n",
      " activation_311 (Activation)    (None, 12, 12, 96)   0           ['batch_normalization_311[0][0]']\n",
      "                                                                                                  \n",
      " max_pooling2d_14 (MaxPooling2D  (None, 12, 12, 288)  0          ['mixed2[0][0]']                 \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " mixed3 (Concatenate)           (None, 12, 12, 768)  0           ['activation_308[0][0]',         \n",
      "                                                                  'activation_311[0][0]',         \n",
      "                                                                  'max_pooling2d_14[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_316 (Conv2D)            (None, 12, 12, 128)  98304       ['mixed3[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_316 (Batch  (None, 12, 12, 128)  384        ['conv2d_316[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_316 (Activation)    (None, 12, 12, 128)  0           ['batch_normalization_316[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_317 (Conv2D)            (None, 12, 12, 128)  114688      ['activation_316[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_317 (Batch  (None, 12, 12, 128)  384        ['conv2d_317[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_317 (Activation)    (None, 12, 12, 128)  0           ['batch_normalization_317[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_313 (Conv2D)            (None, 12, 12, 128)  98304       ['mixed3[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_318 (Conv2D)            (None, 12, 12, 128)  114688      ['activation_317[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_313 (Batch  (None, 12, 12, 128)  384        ['conv2d_313[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_318 (Batch  (None, 12, 12, 128)  384        ['conv2d_318[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_313 (Activation)    (None, 12, 12, 128)  0           ['batch_normalization_313[0][0]']\n",
      "                                                                                                  \n",
      " activation_318 (Activation)    (None, 12, 12, 128)  0           ['batch_normalization_318[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_314 (Conv2D)            (None, 12, 12, 128)  114688      ['activation_313[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_319 (Conv2D)            (None, 12, 12, 128)  114688      ['activation_318[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_314 (Batch  (None, 12, 12, 128)  384        ['conv2d_314[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_319 (Batch  (None, 12, 12, 128)  384        ['conv2d_319[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_314 (Activation)    (None, 12, 12, 128)  0           ['batch_normalization_314[0][0]']\n",
      "                                                                                                  \n",
      " activation_319 (Activation)    (None, 12, 12, 128)  0           ['batch_normalization_319[0][0]']\n",
      "                                                                                                  \n",
      " average_pooling2d_30 (AverageP  (None, 12, 12, 768)  0          ['mixed3[0][0]']                 \n",
      " ooling2D)                                                                                        \n",
      "                                                                                                  \n",
      " conv2d_312 (Conv2D)            (None, 12, 12, 192)  147456      ['mixed3[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_315 (Conv2D)            (None, 12, 12, 192)  172032      ['activation_314[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_320 (Conv2D)            (None, 12, 12, 192)  172032      ['activation_319[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_321 (Conv2D)            (None, 12, 12, 192)  147456      ['average_pooling2d_30[0][0]']   \n",
      "                                                                                                  \n",
      " batch_normalization_312 (Batch  (None, 12, 12, 192)  576        ['conv2d_312[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_315 (Batch  (None, 12, 12, 192)  576        ['conv2d_315[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_320 (Batch  (None, 12, 12, 192)  576        ['conv2d_320[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_321 (Batch  (None, 12, 12, 192)  576        ['conv2d_321[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_312 (Activation)    (None, 12, 12, 192)  0           ['batch_normalization_312[0][0]']\n",
      "                                                                                                  \n",
      " activation_315 (Activation)    (None, 12, 12, 192)  0           ['batch_normalization_315[0][0]']\n",
      "                                                                                                  \n",
      " activation_320 (Activation)    (None, 12, 12, 192)  0           ['batch_normalization_320[0][0]']\n",
      "                                                                                                  \n",
      " activation_321 (Activation)    (None, 12, 12, 192)  0           ['batch_normalization_321[0][0]']\n",
      "                                                                                                  \n",
      " mixed4 (Concatenate)           (None, 12, 12, 768)  0           ['activation_312[0][0]',         \n",
      "                                                                  'activation_315[0][0]',         \n",
      "                                                                  'activation_320[0][0]',         \n",
      "                                                                  'activation_321[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_326 (Conv2D)            (None, 12, 12, 160)  122880      ['mixed4[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_326 (Batch  (None, 12, 12, 160)  480        ['conv2d_326[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_326 (Activation)    (None, 12, 12, 160)  0           ['batch_normalization_326[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_327 (Conv2D)            (None, 12, 12, 160)  179200      ['activation_326[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_327 (Batch  (None, 12, 12, 160)  480        ['conv2d_327[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_327 (Activation)    (None, 12, 12, 160)  0           ['batch_normalization_327[0][0]']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/DATA/projects/monkey pox project/venv/lib/python3.10/site-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " conv2d_323 (Conv2D)            (None, 12, 12, 160)  122880      ['mixed4[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_328 (Conv2D)            (None, 12, 12, 160)  179200      ['activation_327[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_323 (Batch  (None, 12, 12, 160)  480        ['conv2d_323[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_328 (Batch  (None, 12, 12, 160)  480        ['conv2d_328[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_323 (Activation)    (None, 12, 12, 160)  0           ['batch_normalization_323[0][0]']\n",
      "                                                                                                  \n",
      " activation_328 (Activation)    (None, 12, 12, 160)  0           ['batch_normalization_328[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_324 (Conv2D)            (None, 12, 12, 160)  179200      ['activation_323[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_329 (Conv2D)            (None, 12, 12, 160)  179200      ['activation_328[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_324 (Batch  (None, 12, 12, 160)  480        ['conv2d_324[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_329 (Batch  (None, 12, 12, 160)  480        ['conv2d_329[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_324 (Activation)    (None, 12, 12, 160)  0           ['batch_normalization_324[0][0]']\n",
      "                                                                                                  \n",
      " activation_329 (Activation)    (None, 12, 12, 160)  0           ['batch_normalization_329[0][0]']\n",
      "                                                                                                  \n",
      " average_pooling2d_31 (AverageP  (None, 12, 12, 768)  0          ['mixed4[0][0]']                 \n",
      " ooling2D)                                                                                        \n",
      "                                                                                                  \n",
      " conv2d_322 (Conv2D)            (None, 12, 12, 192)  147456      ['mixed4[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_325 (Conv2D)            (None, 12, 12, 192)  215040      ['activation_324[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_330 (Conv2D)            (None, 12, 12, 192)  215040      ['activation_329[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_331 (Conv2D)            (None, 12, 12, 192)  147456      ['average_pooling2d_31[0][0]']   \n",
      "                                                                                                  \n",
      " batch_normalization_322 (Batch  (None, 12, 12, 192)  576        ['conv2d_322[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_325 (Batch  (None, 12, 12, 192)  576        ['conv2d_325[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_330 (Batch  (None, 12, 12, 192)  576        ['conv2d_330[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_331 (Batch  (None, 12, 12, 192)  576        ['conv2d_331[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_322 (Activation)    (None, 12, 12, 192)  0           ['batch_normalization_322[0][0]']\n",
      "                                                                                                  \n",
      " activation_325 (Activation)    (None, 12, 12, 192)  0           ['batch_normalization_325[0][0]']\n",
      "                                                                                                  \n",
      " activation_330 (Activation)    (None, 12, 12, 192)  0           ['batch_normalization_330[0][0]']\n",
      "                                                                                                  \n",
      " activation_331 (Activation)    (None, 12, 12, 192)  0           ['batch_normalization_331[0][0]']\n",
      "                                                                                                  \n",
      " mixed5 (Concatenate)           (None, 12, 12, 768)  0           ['activation_322[0][0]',         \n",
      "                                                                  'activation_325[0][0]',         \n",
      "                                                                  'activation_330[0][0]',         \n",
      "                                                                  'activation_331[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_336 (Conv2D)            (None, 12, 12, 160)  122880      ['mixed5[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_336 (Batch  (None, 12, 12, 160)  480        ['conv2d_336[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_336 (Activation)    (None, 12, 12, 160)  0           ['batch_normalization_336[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_337 (Conv2D)            (None, 12, 12, 160)  179200      ['activation_336[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_337 (Batch  (None, 12, 12, 160)  480        ['conv2d_337[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_337 (Activation)    (None, 12, 12, 160)  0           ['batch_normalization_337[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_333 (Conv2D)            (None, 12, 12, 160)  122880      ['mixed5[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_338 (Conv2D)            (None, 12, 12, 160)  179200      ['activation_337[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_333 (Batch  (None, 12, 12, 160)  480        ['conv2d_333[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_338 (Batch  (None, 12, 12, 160)  480        ['conv2d_338[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_333 (Activation)    (None, 12, 12, 160)  0           ['batch_normalization_333[0][0]']\n",
      "                                                                                                  \n",
      " activation_338 (Activation)    (None, 12, 12, 160)  0           ['batch_normalization_338[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_334 (Conv2D)            (None, 12, 12, 160)  179200      ['activation_333[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_339 (Conv2D)            (None, 12, 12, 160)  179200      ['activation_338[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_334 (Batch  (None, 12, 12, 160)  480        ['conv2d_334[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_339 (Batch  (None, 12, 12, 160)  480        ['conv2d_339[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_334 (Activation)    (None, 12, 12, 160)  0           ['batch_normalization_334[0][0]']\n",
      "                                                                                                  \n",
      " activation_339 (Activation)    (None, 12, 12, 160)  0           ['batch_normalization_339[0][0]']\n",
      "                                                                                                  \n",
      " average_pooling2d_32 (AverageP  (None, 12, 12, 768)  0          ['mixed5[0][0]']                 \n",
      " ooling2D)                                                                                        \n",
      "                                                                                                  \n",
      " conv2d_332 (Conv2D)            (None, 12, 12, 192)  147456      ['mixed5[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_335 (Conv2D)            (None, 12, 12, 192)  215040      ['activation_334[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_340 (Conv2D)            (None, 12, 12, 192)  215040      ['activation_339[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_341 (Conv2D)            (None, 12, 12, 192)  147456      ['average_pooling2d_32[0][0]']   \n",
      "                                                                                                  \n",
      " batch_normalization_332 (Batch  (None, 12, 12, 192)  576        ['conv2d_332[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_335 (Batch  (None, 12, 12, 192)  576        ['conv2d_335[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_340 (Batch  (None, 12, 12, 192)  576        ['conv2d_340[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_341 (Batch  (None, 12, 12, 192)  576        ['conv2d_341[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_332 (Activation)    (None, 12, 12, 192)  0           ['batch_normalization_332[0][0]']\n",
      "                                                                                                  \n",
      " activation_335 (Activation)    (None, 12, 12, 192)  0           ['batch_normalization_335[0][0]']\n",
      "                                                                                                  \n",
      " activation_340 (Activation)    (None, 12, 12, 192)  0           ['batch_normalization_340[0][0]']\n",
      "                                                                                                  \n",
      " activation_341 (Activation)    (None, 12, 12, 192)  0           ['batch_normalization_341[0][0]']\n",
      "                                                                                                  \n",
      " mixed6 (Concatenate)           (None, 12, 12, 768)  0           ['activation_332[0][0]',         \n",
      "                                                                  'activation_335[0][0]',         \n",
      "                                                                  'activation_340[0][0]',         \n",
      "                                                                  'activation_341[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_346 (Conv2D)            (None, 12, 12, 192)  147456      ['mixed6[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_346 (Batch  (None, 12, 12, 192)  576        ['conv2d_346[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_346 (Activation)    (None, 12, 12, 192)  0           ['batch_normalization_346[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_347 (Conv2D)            (None, 12, 12, 192)  258048      ['activation_346[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_347 (Batch  (None, 12, 12, 192)  576        ['conv2d_347[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_347 (Activation)    (None, 12, 12, 192)  0           ['batch_normalization_347[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_343 (Conv2D)            (None, 12, 12, 192)  147456      ['mixed6[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_348 (Conv2D)            (None, 12, 12, 192)  258048      ['activation_347[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_343 (Batch  (None, 12, 12, 192)  576        ['conv2d_343[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_348 (Batch  (None, 12, 12, 192)  576        ['conv2d_348[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_343 (Activation)    (None, 12, 12, 192)  0           ['batch_normalization_343[0][0]']\n",
      "                                                                                                  \n",
      " activation_348 (Activation)    (None, 12, 12, 192)  0           ['batch_normalization_348[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_344 (Conv2D)            (None, 12, 12, 192)  258048      ['activation_343[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_349 (Conv2D)            (None, 12, 12, 192)  258048      ['activation_348[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_344 (Batch  (None, 12, 12, 192)  576        ['conv2d_344[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_349 (Batch  (None, 12, 12, 192)  576        ['conv2d_349[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_344 (Activation)    (None, 12, 12, 192)  0           ['batch_normalization_344[0][0]']\n",
      "                                                                                                  \n",
      " activation_349 (Activation)    (None, 12, 12, 192)  0           ['batch_normalization_349[0][0]']\n",
      "                                                                                                  \n",
      " average_pooling2d_33 (AverageP  (None, 12, 12, 768)  0          ['mixed6[0][0]']                 \n",
      " ooling2D)                                                                                        \n",
      "                                                                                                  \n",
      " conv2d_342 (Conv2D)            (None, 12, 12, 192)  147456      ['mixed6[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_345 (Conv2D)            (None, 12, 12, 192)  258048      ['activation_344[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_350 (Conv2D)            (None, 12, 12, 192)  258048      ['activation_349[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_351 (Conv2D)            (None, 12, 12, 192)  147456      ['average_pooling2d_33[0][0]']   \n",
      "                                                                                                  \n",
      " batch_normalization_342 (Batch  (None, 12, 12, 192)  576        ['conv2d_342[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_345 (Batch  (None, 12, 12, 192)  576        ['conv2d_345[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_350 (Batch  (None, 12, 12, 192)  576        ['conv2d_350[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_351 (Batch  (None, 12, 12, 192)  576        ['conv2d_351[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_342 (Activation)    (None, 12, 12, 192)  0           ['batch_normalization_342[0][0]']\n",
      "                                                                                                  \n",
      " activation_345 (Activation)    (None, 12, 12, 192)  0           ['batch_normalization_345[0][0]']\n",
      "                                                                                                  \n",
      " activation_350 (Activation)    (None, 12, 12, 192)  0           ['batch_normalization_350[0][0]']\n",
      "                                                                                                  \n",
      " activation_351 (Activation)    (None, 12, 12, 192)  0           ['batch_normalization_351[0][0]']\n",
      "                                                                                                  \n",
      " mixed7 (Concatenate)           (None, 12, 12, 768)  0           ['activation_342[0][0]',         \n",
      "                                                                  'activation_345[0][0]',         \n",
      "                                                                  'activation_350[0][0]',         \n",
      "                                                                  'activation_351[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_354 (Conv2D)            (None, 12, 12, 192)  147456      ['mixed7[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_354 (Batch  (None, 12, 12, 192)  576        ['conv2d_354[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_354 (Activation)    (None, 12, 12, 192)  0           ['batch_normalization_354[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_355 (Conv2D)            (None, 12, 12, 192)  258048      ['activation_354[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_355 (Batch  (None, 12, 12, 192)  576        ['conv2d_355[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_355 (Activation)    (None, 12, 12, 192)  0           ['batch_normalization_355[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_352 (Conv2D)            (None, 12, 12, 192)  147456      ['mixed7[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_356 (Conv2D)            (None, 12, 12, 192)  258048      ['activation_355[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_352 (Batch  (None, 12, 12, 192)  576        ['conv2d_352[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_356 (Batch  (None, 12, 12, 192)  576        ['conv2d_356[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_352 (Activation)    (None, 12, 12, 192)  0           ['batch_normalization_352[0][0]']\n",
      "                                                                                                  \n",
      " activation_356 (Activation)    (None, 12, 12, 192)  0           ['batch_normalization_356[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_353 (Conv2D)            (None, 5, 5, 320)    552960      ['activation_352[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_357 (Conv2D)            (None, 5, 5, 192)    331776      ['activation_356[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_353 (Batch  (None, 5, 5, 320)   960         ['conv2d_353[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_357 (Batch  (None, 5, 5, 192)   576         ['conv2d_357[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_353 (Activation)    (None, 5, 5, 320)    0           ['batch_normalization_353[0][0]']\n",
      "                                                                                                  \n",
      " activation_357 (Activation)    (None, 5, 5, 192)    0           ['batch_normalization_357[0][0]']\n",
      "                                                                                                  \n",
      " max_pooling2d_15 (MaxPooling2D  (None, 5, 5, 768)   0           ['mixed7[0][0]']                 \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " mixed8 (Concatenate)           (None, 5, 5, 1280)   0           ['activation_353[0][0]',         \n",
      "                                                                  'activation_357[0][0]',         \n",
      "                                                                  'max_pooling2d_15[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_362 (Conv2D)            (None, 5, 5, 448)    573440      ['mixed8[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_362 (Batch  (None, 5, 5, 448)   1344        ['conv2d_362[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_362 (Activation)    (None, 5, 5, 448)    0           ['batch_normalization_362[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_359 (Conv2D)            (None, 5, 5, 384)    491520      ['mixed8[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_363 (Conv2D)            (None, 5, 5, 384)    1548288     ['activation_362[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_359 (Batch  (None, 5, 5, 384)   1152        ['conv2d_359[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_363 (Batch  (None, 5, 5, 384)   1152        ['conv2d_363[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_359 (Activation)    (None, 5, 5, 384)    0           ['batch_normalization_359[0][0]']\n",
      "                                                                                                  \n",
      " activation_363 (Activation)    (None, 5, 5, 384)    0           ['batch_normalization_363[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_360 (Conv2D)            (None, 5, 5, 384)    442368      ['activation_359[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_361 (Conv2D)            (None, 5, 5, 384)    442368      ['activation_359[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_364 (Conv2D)            (None, 5, 5, 384)    442368      ['activation_363[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_365 (Conv2D)            (None, 5, 5, 384)    442368      ['activation_363[0][0]']         \n",
      "                                                                                                  \n",
      " average_pooling2d_34 (AverageP  (None, 5, 5, 1280)  0           ['mixed8[0][0]']                 \n",
      " ooling2D)                                                                                        \n",
      "                                                                                                  \n",
      " conv2d_358 (Conv2D)            (None, 5, 5, 320)    409600      ['mixed8[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_360 (Batch  (None, 5, 5, 384)   1152        ['conv2d_360[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_361 (Batch  (None, 5, 5, 384)   1152        ['conv2d_361[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_364 (Batch  (None, 5, 5, 384)   1152        ['conv2d_364[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_365 (Batch  (None, 5, 5, 384)   1152        ['conv2d_365[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " conv2d_366 (Conv2D)            (None, 5, 5, 192)    245760      ['average_pooling2d_34[0][0]']   \n",
      "                                                                                                  \n",
      " batch_normalization_358 (Batch  (None, 5, 5, 320)   960         ['conv2d_358[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_360 (Activation)    (None, 5, 5, 384)    0           ['batch_normalization_360[0][0]']\n",
      "                                                                                                  \n",
      " activation_361 (Activation)    (None, 5, 5, 384)    0           ['batch_normalization_361[0][0]']\n",
      "                                                                                                  \n",
      " activation_364 (Activation)    (None, 5, 5, 384)    0           ['batch_normalization_364[0][0]']\n",
      "                                                                                                  \n",
      " activation_365 (Activation)    (None, 5, 5, 384)    0           ['batch_normalization_365[0][0]']\n",
      "                                                                                                  \n",
      " batch_normalization_366 (Batch  (None, 5, 5, 192)   576         ['conv2d_366[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_358 (Activation)    (None, 5, 5, 320)    0           ['batch_normalization_358[0][0]']\n",
      "                                                                                                  \n",
      " mixed9_0 (Concatenate)         (None, 5, 5, 768)    0           ['activation_360[0][0]',         \n",
      "                                                                  'activation_361[0][0]']         \n",
      "                                                                                                  \n",
      " concatenate_6 (Concatenate)    (None, 5, 5, 768)    0           ['activation_364[0][0]',         \n",
      "                                                                  'activation_365[0][0]']         \n",
      "                                                                                                  \n",
      " activation_366 (Activation)    (None, 5, 5, 192)    0           ['batch_normalization_366[0][0]']\n",
      "                                                                                                  \n",
      " mixed9 (Concatenate)           (None, 5, 5, 2048)   0           ['activation_358[0][0]',         \n",
      "                                                                  'mixed9_0[0][0]',               \n",
      "                                                                  'concatenate_6[0][0]',          \n",
      "                                                                  'activation_366[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_371 (Conv2D)            (None, 5, 5, 448)    917504      ['mixed9[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_371 (Batch  (None, 5, 5, 448)   1344        ['conv2d_371[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_371 (Activation)    (None, 5, 5, 448)    0           ['batch_normalization_371[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_368 (Conv2D)            (None, 5, 5, 384)    786432      ['mixed9[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_372 (Conv2D)            (None, 5, 5, 384)    1548288     ['activation_371[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_368 (Batch  (None, 5, 5, 384)   1152        ['conv2d_368[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_372 (Batch  (None, 5, 5, 384)   1152        ['conv2d_372[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_368 (Activation)    (None, 5, 5, 384)    0           ['batch_normalization_368[0][0]']\n",
      "                                                                                                  \n",
      " activation_372 (Activation)    (None, 5, 5, 384)    0           ['batch_normalization_372[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_369 (Conv2D)            (None, 5, 5, 384)    442368      ['activation_368[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_370 (Conv2D)            (None, 5, 5, 384)    442368      ['activation_368[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_373 (Conv2D)            (None, 5, 5, 384)    442368      ['activation_372[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_374 (Conv2D)            (None, 5, 5, 384)    442368      ['activation_372[0][0]']         \n",
      "                                                                                                  \n",
      " average_pooling2d_35 (AverageP  (None, 5, 5, 2048)  0           ['mixed9[0][0]']                 \n",
      " ooling2D)                                                                                        \n",
      "                                                                                                  \n",
      " conv2d_367 (Conv2D)            (None, 5, 5, 320)    655360      ['mixed9[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_369 (Batch  (None, 5, 5, 384)   1152        ['conv2d_369[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_370 (Batch  (None, 5, 5, 384)   1152        ['conv2d_370[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_373 (Batch  (None, 5, 5, 384)   1152        ['conv2d_373[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_374 (Batch  (None, 5, 5, 384)   1152        ['conv2d_374[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " conv2d_375 (Conv2D)            (None, 5, 5, 192)    393216      ['average_pooling2d_35[0][0]']   \n",
      "                                                                                                  \n",
      " batch_normalization_367 (Batch  (None, 5, 5, 320)   960         ['conv2d_367[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_369 (Activation)    (None, 5, 5, 384)    0           ['batch_normalization_369[0][0]']\n",
      "                                                                                                  \n",
      " activation_370 (Activation)    (None, 5, 5, 384)    0           ['batch_normalization_370[0][0]']\n",
      "                                                                                                  \n",
      " activation_373 (Activation)    (None, 5, 5, 384)    0           ['batch_normalization_373[0][0]']\n",
      "                                                                                                  \n",
      " activation_374 (Activation)    (None, 5, 5, 384)    0           ['batch_normalization_374[0][0]']\n",
      "                                                                                                  \n",
      " batch_normalization_375 (Batch  (None, 5, 5, 192)   576         ['conv2d_375[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_367 (Activation)    (None, 5, 5, 320)    0           ['batch_normalization_367[0][0]']\n",
      "                                                                                                  \n",
      " mixed9_1 (Concatenate)         (None, 5, 5, 768)    0           ['activation_369[0][0]',         \n",
      "                                                                  'activation_370[0][0]']         \n",
      "                                                                                                  \n",
      " concatenate_7 (Concatenate)    (None, 5, 5, 768)    0           ['activation_373[0][0]',         \n",
      "                                                                  'activation_374[0][0]']         \n",
      "                                                                                                  \n",
      " activation_375 (Activation)    (None, 5, 5, 192)    0           ['batch_normalization_375[0][0]']\n",
      "                                                                                                  \n",
      " mixed10 (Concatenate)          (None, 5, 5, 2048)   0           ['activation_367[0][0]',         \n",
      "                                                                  'mixed9_1[0][0]',               \n",
      "                                                                  'concatenate_7[0][0]',          \n",
      "                                                                  'activation_375[0][0]']         \n",
      "                                                                                                  \n",
      " dropout_6 (Dropout)            (None, 5, 5, 2048)   0           ['mixed10[0][0]']                \n",
      "                                                                                                  \n",
      " flatten_3 (Flatten)            (None, 51200)        0           ['dropout_6[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_7 (Dropout)            (None, 51200)        0           ['flatten_3[0][0]']              \n",
      "                                                                                                  \n",
      " dense_8 (Dense)                (None, 256)          13107456    ['dropout_7[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_8 (Dropout)            (None, 256)          0           ['dense_8[0][0]']                \n",
      "                                                                                                  \n",
      " dense_9 (Dense)                (None, 128)          32896       ['dropout_8[0][0]']              \n",
      "                                                                                                  \n",
      " dense_10 (Dense)               (None, 1)            129         ['dense_9[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 34,943,265\n",
      "Trainable params: 13,140,481\n",
      "Non-trainable params: 21,802,784\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model3 = create_model_transfer()\n",
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2142 files belonging to 2 classes.\n",
      "Found 420 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator, test_generator = create_generator_without_augmentation(train_dir_1, test_dir_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "134/134 [==============================] - 15s 88ms/step - loss: 38.6859 - accuracy: 0.5504 - val_loss: 0.7442 - val_accuracy: 0.6262\n",
      "Epoch 2/25\n",
      "134/134 [==============================] - 11s 82ms/step - loss: 0.6901 - accuracy: 0.5551 - val_loss: 0.6519 - val_accuracy: 0.6548\n",
      "Epoch 3/25\n",
      "134/134 [==============================] - 11s 83ms/step - loss: 0.6761 - accuracy: 0.5826 - val_loss: 0.5855 - val_accuracy: 0.7405\n",
      "Epoch 4/25\n",
      "134/134 [==============================] - 11s 83ms/step - loss: 0.6575 - accuracy: 0.6022 - val_loss: 0.5548 - val_accuracy: 0.7452\n",
      "Epoch 5/25\n",
      "134/134 [==============================] - 11s 83ms/step - loss: 0.6706 - accuracy: 0.5994 - val_loss: 0.5741 - val_accuracy: 0.7548\n",
      "Epoch 6/25\n",
      "134/134 [==============================] - 11s 83ms/step - loss: 0.6338 - accuracy: 0.6275 - val_loss: 0.5407 - val_accuracy: 0.7548\n",
      "Epoch 7/25\n",
      "134/134 [==============================] - 11s 84ms/step - loss: 0.6497 - accuracy: 0.6158 - val_loss: 0.5438 - val_accuracy: 0.7595\n",
      "Epoch 8/25\n",
      "134/134 [==============================] - 11s 84ms/step - loss: 0.6509 - accuracy: 0.6083 - val_loss: 0.5771 - val_accuracy: 0.7286\n",
      "Epoch 9/25\n",
      "134/134 [==============================] - 11s 84ms/step - loss: 0.6775 - accuracy: 0.5691 - val_loss: 0.7034 - val_accuracy: 0.6048\n",
      "Epoch 10/25\n",
      "134/134 [==============================] - 11s 84ms/step - loss: 0.6872 - accuracy: 0.5532 - val_loss: 0.6774 - val_accuracy: 0.6024\n",
      "Epoch 11/25\n",
      "134/134 [==============================] - 11s 84ms/step - loss: 0.6808 - accuracy: 0.5556 - val_loss: 0.6740 - val_accuracy: 0.6119\n",
      "Epoch 12/25\n",
      "134/134 [==============================] - 11s 84ms/step - loss: 0.7875 - accuracy: 0.5607 - val_loss: 0.6683 - val_accuracy: 0.6262\n",
      "Epoch 13/25\n",
      "134/134 [==============================] - 11s 84ms/step - loss: 0.6935 - accuracy: 0.5724 - val_loss: 0.6606 - val_accuracy: 0.6333\n",
      "Epoch 14/25\n",
      "134/134 [==============================] - 11s 85ms/step - loss: 0.6780 - accuracy: 0.5593 - val_loss: 0.6472 - val_accuracy: 0.6571\n",
      "Epoch 15/25\n",
      "134/134 [==============================] - 11s 84ms/step - loss: 0.6745 - accuracy: 0.5710 - val_loss: 0.6581 - val_accuracy: 0.6262\n",
      "Epoch 16/25\n",
      "134/134 [==============================] - 11s 84ms/step - loss: 0.6744 - accuracy: 0.5705 - val_loss: 0.6254 - val_accuracy: 0.6976\n",
      "Epoch 17/25\n",
      "134/134 [==============================] - 11s 84ms/step - loss: 0.7064 - accuracy: 0.5556 - val_loss: 0.6715 - val_accuracy: 0.6095\n",
      "Epoch 18/25\n",
      "134/134 [==============================] - 11s 84ms/step - loss: 0.6800 - accuracy: 0.5542 - val_loss: 0.6781 - val_accuracy: 0.6024\n",
      "Epoch 19/25\n",
      "134/134 [==============================] - 11s 84ms/step - loss: 0.6949 - accuracy: 0.5602 - val_loss: 0.8119 - val_accuracy: 0.6024\n",
      "Epoch 20/25\n",
      "134/134 [==============================] - 11s 84ms/step - loss: 0.6788 - accuracy: 0.5626 - val_loss: 0.6560 - val_accuracy: 0.6381\n",
      "Epoch 21/25\n",
      "134/134 [==============================] - 11s 85ms/step - loss: 0.6806 - accuracy: 0.5584 - val_loss: 0.6708 - val_accuracy: 0.6119\n",
      "Epoch 22/25\n",
      "134/134 [==============================] - 12s 87ms/step - loss: 0.6851 - accuracy: 0.5612 - val_loss: 0.6626 - val_accuracy: 0.6190\n",
      "Epoch 23/25\n",
      "134/134 [==============================] - 11s 83ms/step - loss: 0.6794 - accuracy: 0.5546 - val_loss: 0.6756 - val_accuracy: 0.6095\n",
      "Epoch 24/25\n",
      "134/134 [==============================] - 11s 84ms/step - loss: 0.6763 - accuracy: 0.5584 - val_loss: 0.6729 - val_accuracy: 0.6071\n",
      "Epoch 25/25\n",
      "134/134 [==============================] - 12s 86ms/step - loss: 0.6792 - accuracy: 0.5556 - val_loss: 0.6573 - val_accuracy: 0.6262\n"
     ]
    }
   ],
   "source": [
    "history3 = model3.fit(\n",
    "    train_generator,\n",
    "    epochs=25,\n",
    "    validation_data=test_generator,\n",
    "    steps_per_epoch=len(train_generator)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'acc'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/media/DATA/projects/monkey pox project/notebooks/workbook2.ipynb Cell 22\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/media/DATA/projects/monkey%20pox%20project/notebooks/workbook2.ipynb#ch0000017?line=0'>1</a>\u001b[0m plot_history(history3)\n",
      "\u001b[1;32m/media/DATA/projects/monkey pox project/notebooks/workbook2.ipynb Cell 22\u001b[0m in \u001b[0;36mplot_history\u001b[0;34m(history)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/media/DATA/projects/monkey%20pox%20project/notebooks/workbook2.ipynb#ch0000017?line=2'>3</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mplot_history\u001b[39m(history):\n\u001b[0;32m----> <a href='vscode-notebook-cell:/media/DATA/projects/monkey%20pox%20project/notebooks/workbook2.ipynb#ch0000017?line=3'>4</a>\u001b[0m     acc \u001b[39m=\u001b[39m history\u001b[39m.\u001b[39;49mhistory[\u001b[39m\"\u001b[39;49m\u001b[39macc\u001b[39;49m\u001b[39m\"\u001b[39;49m]\n\u001b[1;32m      <a href='vscode-notebook-cell:/media/DATA/projects/monkey%20pox%20project/notebooks/workbook2.ipynb#ch0000017?line=4'>5</a>\u001b[0m     val_acc \u001b[39m=\u001b[39m history\u001b[39m.\u001b[39mhistory[\u001b[39m\"\u001b[39m\u001b[39mval_acc\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m      <a href='vscode-notebook-cell:/media/DATA/projects/monkey%20pox%20project/notebooks/workbook2.ipynb#ch0000017?line=5'>6</a>\u001b[0m     loss \u001b[39m=\u001b[39m history\u001b[39m.\u001b[39mhistory[\u001b[39m\"\u001b[39m\u001b[39mloss\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "\u001b[0;31mKeyError\u001b[0m: 'acc'"
     ]
    }
   ],
   "source": [
    "plot_history(history3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import EfficientNetB3\n",
    "from keras.layers import Input\n",
    "def model123():\n",
    "  base_model = EfficientNetB3(include_top=False)\n",
    "  base_model.trainable = True\n",
    "\n",
    "  for layer in base_model.layers[:-5]:\n",
    "    layer.trainable = False\n",
    "\n",
    "  inputs = Input(shape=(224, 224, 3), name=\"input_layer\")\n",
    "  base_layer = base_model(inputs)\n",
    "  dropout_layer_1 = Dropout(0.5)(base_layer)\n",
    "  flat_layer = Flatten()(dropout_layer_1)\n",
    "  dense_1 = Dense(256, activation=\"relu\")(flat_layer)\n",
    "  dropout_layer_2 = Dropout(0.5)(dense_1)\n",
    "  dense_2 = Dense(128, activation=\"relu\")(dropout_layer_2)\n",
    "  outputs = Dense(1, activation=\"sigmoid\")(dense_2)\n",
    "  model = Model(inputs, outputs)\n",
    "  model.compile(optimizer=tf.keras.optimizers.Adam(lr=0.001),\n",
    "                loss='binary_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_layer (InputLayer)    [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " efficientnetb3 (Functional)  (None, None, None, 1536)  10783535 \n",
      "                                                                 \n",
      " dropout_19 (Dropout)        (None, 7, 7, 1536)        0         \n",
      "                                                                 \n",
      " flatten_9 (Flatten)         (None, 75264)             0         \n",
      "                                                                 \n",
      " dense_26 (Dense)            (None, 256)               19267840  \n",
      "                                                                 \n",
      " dropout_20 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_27 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_28 (Dense)            (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 30,084,400\n",
      "Trainable params: 19,893,761\n",
      "Non-trainable params: 10,190,639\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/DATA/projects/monkey pox project/venv/lib/python3.10/site-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 41s 232ms/step - loss: 1.0998 - accuracy: 0.8268 - val_loss: 1.1171 - val_accuracy: 0.7714\n",
      "Epoch 2/50\n",
      "134/134 [==============================] - 21s 155ms/step - loss: 0.5849 - accuracy: 0.9104 - val_loss: 1.0297 - val_accuracy: 0.7929\n",
      "Epoch 3/50\n",
      "134/134 [==============================] - 21s 155ms/step - loss: 0.3147 - accuracy: 0.9468 - val_loss: 1.0999 - val_accuracy: 0.7571\n",
      "Epoch 4/50\n",
      "134/134 [==============================] - 21s 156ms/step - loss: 0.2376 - accuracy: 0.9566 - val_loss: 0.6200 - val_accuracy: 0.8619\n",
      "Epoch 5/50\n",
      "134/134 [==============================] - 21s 155ms/step - loss: 0.0945 - accuracy: 0.9753 - val_loss: 1.7904 - val_accuracy: 0.7381\n",
      "Epoch 6/50\n",
      "134/134 [==============================] - 21s 155ms/step - loss: 0.1279 - accuracy: 0.9725 - val_loss: 1.0791 - val_accuracy: 0.8357\n",
      "Epoch 7/50\n",
      "134/134 [==============================] - 21s 155ms/step - loss: 0.0943 - accuracy: 0.9795 - val_loss: 1.1750 - val_accuracy: 0.8095\n",
      "Epoch 8/50\n",
      "134/134 [==============================] - 21s 155ms/step - loss: 0.0674 - accuracy: 0.9827 - val_loss: 1.8986 - val_accuracy: 0.7262\n",
      "Epoch 9/50\n",
      "134/134 [==============================] - 21s 155ms/step - loss: 0.0543 - accuracy: 0.9902 - val_loss: 0.8998 - val_accuracy: 0.8571\n",
      "Epoch 10/50\n",
      "134/134 [==============================] - 21s 155ms/step - loss: 0.0635 - accuracy: 0.9837 - val_loss: 1.4901 - val_accuracy: 0.7929\n",
      "Epoch 11/50\n",
      "134/134 [==============================] - 21s 155ms/step - loss: 0.1288 - accuracy: 0.9790 - val_loss: 1.3457 - val_accuracy: 0.7714\n",
      "Epoch 12/50\n",
      "134/134 [==============================] - 21s 155ms/step - loss: 0.0569 - accuracy: 0.9883 - val_loss: 1.4242 - val_accuracy: 0.7857\n",
      "Epoch 13/50\n",
      "134/134 [==============================] - 21s 155ms/step - loss: 0.0869 - accuracy: 0.9809 - val_loss: 1.0112 - val_accuracy: 0.8429\n",
      "Epoch 14/50\n",
      "134/134 [==============================] - 21s 156ms/step - loss: 0.1367 - accuracy: 0.9720 - val_loss: 1.3714 - val_accuracy: 0.8262\n",
      "Epoch 15/50\n",
      "134/134 [==============================] - 21s 155ms/step - loss: 0.0668 - accuracy: 0.9837 - val_loss: 1.3385 - val_accuracy: 0.8286\n",
      "Epoch 16/50\n",
      "134/134 [==============================] - 21s 155ms/step - loss: 0.0706 - accuracy: 0.9823 - val_loss: 1.4807 - val_accuracy: 0.8190\n",
      "Epoch 17/50\n",
      "134/134 [==============================] - 21s 156ms/step - loss: 0.0282 - accuracy: 0.9939 - val_loss: 2.5769 - val_accuracy: 0.7762\n",
      "Epoch 18/50\n",
      "134/134 [==============================] - 21s 155ms/step - loss: 0.0626 - accuracy: 0.9897 - val_loss: 1.9537 - val_accuracy: 0.8214\n",
      "Epoch 19/50\n",
      "134/134 [==============================] - 21s 156ms/step - loss: 0.0405 - accuracy: 0.9907 - val_loss: 2.9164 - val_accuracy: 0.7429\n",
      "Epoch 20/50\n",
      "134/134 [==============================] - 21s 156ms/step - loss: 0.0613 - accuracy: 0.9874 - val_loss: 1.3833 - val_accuracy: 0.8286\n",
      "Epoch 21/50\n",
      "134/134 [==============================] - 21s 155ms/step - loss: 0.0370 - accuracy: 0.9893 - val_loss: 1.7093 - val_accuracy: 0.8262\n",
      "Epoch 22/50\n",
      "134/134 [==============================] - 21s 155ms/step - loss: 0.0197 - accuracy: 0.9935 - val_loss: 1.4361 - val_accuracy: 0.7833\n",
      "Epoch 23/50\n",
      "134/134 [==============================] - 21s 155ms/step - loss: 0.0148 - accuracy: 0.9953 - val_loss: 1.4225 - val_accuracy: 0.8095\n",
      "Epoch 24/50\n",
      "134/134 [==============================] - 21s 155ms/step - loss: 0.0246 - accuracy: 0.9935 - val_loss: 1.1686 - val_accuracy: 0.8429\n",
      "Epoch 25/50\n",
      "134/134 [==============================] - 21s 156ms/step - loss: 0.0124 - accuracy: 0.9949 - val_loss: 1.1902 - val_accuracy: 0.8381\n",
      "Epoch 26/50\n",
      "134/134 [==============================] - 21s 155ms/step - loss: 0.0230 - accuracy: 0.9930 - val_loss: 1.2756 - val_accuracy: 0.8095\n",
      "Epoch 27/50\n",
      "134/134 [==============================] - 21s 156ms/step - loss: 0.0292 - accuracy: 0.9925 - val_loss: 0.4917 - val_accuracy: 0.8952\n",
      "Epoch 28/50\n",
      "134/134 [==============================] - 21s 155ms/step - loss: 0.0154 - accuracy: 0.9967 - val_loss: 1.2387 - val_accuracy: 0.7905\n",
      "Epoch 29/50\n",
      "134/134 [==============================] - 21s 155ms/step - loss: 0.0108 - accuracy: 0.9977 - val_loss: 0.7659 - val_accuracy: 0.8310\n",
      "Epoch 30/50\n",
      "134/134 [==============================] - 21s 155ms/step - loss: 0.0159 - accuracy: 0.9958 - val_loss: 0.6685 - val_accuracy: 0.8548\n",
      "Epoch 31/50\n",
      "134/134 [==============================] - 21s 155ms/step - loss: 0.0125 - accuracy: 0.9958 - val_loss: 0.7970 - val_accuracy: 0.8429\n",
      "Epoch 32/50\n",
      "134/134 [==============================] - 21s 153ms/step - loss: 0.0158 - accuracy: 0.9944 - val_loss: 0.9926 - val_accuracy: 0.7881\n",
      "Epoch 33/50\n",
      "134/134 [==============================] - 21s 154ms/step - loss: 0.0136 - accuracy: 0.9972 - val_loss: 0.7812 - val_accuracy: 0.8214\n",
      "Epoch 34/50\n",
      "134/134 [==============================] - 21s 156ms/step - loss: 0.0197 - accuracy: 0.9925 - val_loss: 1.4256 - val_accuracy: 0.7667\n",
      "Epoch 35/50\n",
      "134/134 [==============================] - 21s 156ms/step - loss: 0.0162 - accuracy: 0.9958 - val_loss: 1.4431 - val_accuracy: 0.8024\n",
      "Epoch 36/50\n",
      "134/134 [==============================] - 21s 156ms/step - loss: 0.0717 - accuracy: 0.9851 - val_loss: 0.9766 - val_accuracy: 0.7833\n",
      "Epoch 37/50\n",
      "134/134 [==============================] - 21s 156ms/step - loss: 0.0577 - accuracy: 0.9879 - val_loss: 1.3013 - val_accuracy: 0.7619\n",
      "Epoch 38/50\n",
      "134/134 [==============================] - 21s 155ms/step - loss: 0.0158 - accuracy: 0.9958 - val_loss: 1.2478 - val_accuracy: 0.7714\n",
      "Epoch 39/50\n",
      "134/134 [==============================] - 21s 155ms/step - loss: 0.0311 - accuracy: 0.9907 - val_loss: 0.6025 - val_accuracy: 0.8143\n",
      "Epoch 40/50\n",
      "134/134 [==============================] - 21s 155ms/step - loss: 0.0299 - accuracy: 0.9911 - val_loss: 1.2374 - val_accuracy: 0.7571\n",
      "Epoch 41/50\n",
      "134/134 [==============================] - 21s 156ms/step - loss: 0.0413 - accuracy: 0.9897 - val_loss: 0.9818 - val_accuracy: 0.7714\n",
      "Epoch 42/50\n",
      "134/134 [==============================] - 21s 155ms/step - loss: 0.0085 - accuracy: 0.9972 - val_loss: 1.1721 - val_accuracy: 0.7905\n",
      "Epoch 43/50\n",
      "134/134 [==============================] - 21s 155ms/step - loss: 0.0136 - accuracy: 0.9958 - val_loss: 1.2386 - val_accuracy: 0.7738\n",
      "Epoch 44/50\n",
      "134/134 [==============================] - 21s 155ms/step - loss: 0.0116 - accuracy: 0.9967 - val_loss: 1.1987 - val_accuracy: 0.8143\n",
      "Epoch 45/50\n",
      "134/134 [==============================] - 21s 155ms/step - loss: 0.0398 - accuracy: 0.9921 - val_loss: 1.3540 - val_accuracy: 0.7976\n",
      "Epoch 46/50\n",
      "134/134 [==============================] - 21s 155ms/step - loss: 0.0525 - accuracy: 0.9907 - val_loss: 1.8220 - val_accuracy: 0.7071\n",
      "Epoch 47/50\n",
      "134/134 [==============================] - 21s 156ms/step - loss: 0.0308 - accuracy: 0.9911 - val_loss: 1.2825 - val_accuracy: 0.7167\n",
      "Epoch 48/50\n",
      "134/134 [==============================] - 21s 155ms/step - loss: 0.0085 - accuracy: 0.9977 - val_loss: 1.5934 - val_accuracy: 0.7262\n",
      "Epoch 49/50\n",
      "134/134 [==============================] - 21s 155ms/step - loss: 0.0206 - accuracy: 0.9958 - val_loss: 1.7587 - val_accuracy: 0.7214\n",
      "Epoch 50/50\n",
      "134/134 [==============================] - 21s 155ms/step - loss: 0.0085 - accuracy: 0.9972 - val_loss: 1.3040 - val_accuracy: 0.8000\n"
     ]
    }
   ],
   "source": [
    "model4 = model123()\n",
    "model4.summary()\n",
    "\n",
    "history4 = model4.fit(\n",
    "    train_generator,\n",
    "    epochs=50,\n",
    "    validation_data=test_generator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plot_history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/media/DATA/projects/monkey pox project/notebooks/workbook2.ipynb Cell 25\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/media/DATA/projects/monkey%20pox%20project/notebooks/workbook2.ipynb#ch0000022?line=0'>1</a>\u001b[0m plot_history(history4)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plot_history' is not defined"
     ]
    }
   ],
   "source": [
    "plot_history(history4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(model):\n",
    "    test_data = tf.keras.preprocessing.image_dataset_from_directory(directory=\"../datasets/monkeypox/Fold1/Fold1/Fold1/Test\",\n",
    "                                                                 image_size=(224, 224),\n",
    "                                                                 label_mode=\"binary\",\n",
    "                                                                 batch_size=32,\n",
    "                                                                shuffle=False)\n",
    "    y_pred = tf.math.round(model.predict(test_data))\n",
    "    y_true = []\n",
    "    for images, labels in test_data.unbatch():\n",
    "        y_true.append(labels.numpy())     \n",
    "    print(f\"accuracy_score = {accuracy_score(y_true, y_pred)}\")\n",
    "    print(classification_report(y_true, y_pred, target_names=train_generator.class_names))\n",
    "    \n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    sns.heatmap(cm.astype(\"int\"), annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 45 files belonging to 2 classes.\n",
      "2/2 [==============================] - 0s 198ms/step\n",
      "accuracy_score = 0.9333333333333333\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Monkeypox       0.87      1.00      0.93        20\n",
      "      Others       1.00      0.88      0.94        25\n",
      "\n",
      "    accuracy                           0.93        45\n",
      "   macro avg       0.93      0.94      0.93        45\n",
      "weighted avg       0.94      0.93      0.93        45\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "evaluation(model4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "model4.save(\"../models/model1.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 45 files belonging to 2 classes.\n",
      "2/2 [==============================] - 2s 189ms/step\n",
      "accuracy_score = 0.8222222222222222\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Monkeypox       0.73      0.95      0.83        20\n",
      "      Others       0.95      0.72      0.82        25\n",
      "\n",
      "    accuracy                           0.82        45\n",
      "   macro avg       0.84      0.83      0.82        45\n",
      "weighted avg       0.85      0.82      0.82        45\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "evaluation(model4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 130). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://a9bd8d4e-72e2-4020-b200-e661bf78458a/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://a9bd8d4e-72e2-4020-b200-e661bf78458a/assets\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model(\"../models/model1.h5\")\n",
    "import pickle\n",
    "with open(\"../models/model1_pkl\", \"wb\") as files:\n",
    "    pickle.dump(model, files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "eee47e0ccaca034d6208d835af4063a2be2c5941a553209678f6370f53dd5a61"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
